{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T18:34:44.145850Z",
     "start_time": "2023-04-28T18:34:44.103415Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T18:34:44.146700Z",
     "start_time": "2023-04-28T18:34:44.145423Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ir_dataset does not exist.. downloading\n",
      "Downloading data...\n",
      "Unzipping..\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "data_path = Path(\"\")\n",
    "dataset_path = data_path / \"ir_dataset\"\n",
    "if dataset_path.is_dir():\n",
    "    print(f\"{dataset_path} already exists.. skipping download\")\n",
    "else:\n",
    "    print(f\"{dataset_path} does not exist.. downloading\")\n",
    "    dataset_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Download the dataset\n",
    "    with open(data_path / \"ir-anthology-v1.zip\", \"wb\") as f:\n",
    "        url = \"https://files.webis.de/teaching/ir-ss23/ir-anthology-v1.zip\"\n",
    "        request = requests.get(url)\n",
    "        print(\"Downloading data...\")\n",
    "        f.write(request.content)\n",
    "\n",
    "    with zipfile.ZipFile(data_path / \"ir-anthology-v1.zip\", \"r\") as zip_ref:\n",
    "        print(\"Unzipping..\")\n",
    "        zip_ref.extractall(dataset_path)\n",
    "        print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T18:34:45.015494Z",
     "start_time": "2023-04-28T18:34:44.146076Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': '',\n",
      " 'authors': [],\n",
      " 'booktitle': 'Proceedings of the 4th Joint Workshop on Bibliometric-enhanced '\n",
      "              'Information Retrieval and Natural Language Processing for '\n",
      "              'Digital Libraries (BIRNDL 2019) co-located with the 42nd '\n",
      "              'International ACM SIGIR Conference on Research and Development '\n",
      "              'in Information Retrieval (SIGIR 2019), Paris, France, July 25, '\n",
      "              '2019',\n",
      " 'doc_id': '2019.sigirconf_workshop-2019birndl.0',\n",
      " 'title': 'Proceedings of the 4th Joint Workshop on Bibliometric-enhanced '\n",
      "          'Information Retrieval and Natural Language Processing for Digital '\n",
      "          'Libraries (BIRNDL 2019) co-located with the 42nd International ACM '\n",
      "          'SIGIR Conference on Research and Development in Information '\n",
      "          'Retrieval (SIGIR 2019), Paris, France, July 25, 2019',\n",
      " 'year': '2019'}\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "import pprint\n",
    "\n",
    "with jsonlines.open(dataset_path / \"ir-anthology-07-11-2021-ss23.jsonl\", 'r') as jsonl_f:\n",
    "     lst = [obj for obj in jsonl_f]\n",
    "     # only keep the keys \"id\" and \"title\"\n",
    "     lst = [{k if k != 'id' else 'doc_id': v for k, v in obj.items() if k in ['id', 'title','abstract','authors','year','booktitle']} for obj in lst]\n",
    "     for json_elem in lst:\n",
    "        if 'id' in json_elem:\n",
    "            json_elem['doc_id'] = json_elem.pop('id')\n",
    "\n",
    "     pprint.pprint(lst[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T18:34:45.193099Z",
     "start_time": "2023-04-28T18:34:45.016527Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "processed_path = Path(\"\")\n",
    "processed_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# write the processed data to a jsonl file\n",
    "with jsonlines.open(processed_path / 'ir-anthology-processed.jsonl', 'w') as writer:\n",
    "    writer.write_all(lst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
