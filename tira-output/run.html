<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <link rel="icon"
    href="https://raw.githubusercontent.com/capreolus-ir/diffir/master/docs/images/icon.png">
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
    integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-select@1.13.14/dist/css/bootstrap-select.min.css">
  <title>diffir: IR model comparision</title>
  <style>
    .card {
      margin: 5px !important;
    }

    .highlight {
      background-color: #ffffd3;
    }

    #DocumentOverlay {
      position: fixed;
      top: 0;
      bottom: 0;
      left: 0;
      right: 0;
      background-color: rgba(0, 0, 0, .25);
    }

    #DocumentDetails {
      position: fixed;
      top: 60px;
      left: 10%;
      right: 10%;
      bottom: 60px;
      background-color: white;
      padding: 20px;
      border: 1px solid rgba(0, 0, 0, .125);
      border-radius: 0.25rem;
      box-shadow: 0 0 16px black;
      overflow: auto;
    }

    .close-overlay {
      position: absolute;
      top: 4px;
      right: 4px;
      border-radius: 100%;
      background-color: #111;
      font-size: 17px;
      padding: 9px;
      color: white;
      width: 30px;
      height: 30px;
      text-align: center;
      font-weight: normal;
      line-height: 11px;
      cursor: pointer;
    }

    .docid {
      background-color: rgb(224, 135, 55);
      position: absolute;
      top: 0;
      bottom: 0;
      width: 20px;
      overflow: hidden;
      margin-bottom: 0;
      border-radius: 0;
      font-weight: normal;
      white-space: nowrap;
    }

    .docid-value {
      transform: rotate(90deg);
      font-size: 0.7em;
      padding-left: 8px;
    }

    .fields th {
      vertical-align: top;
      text-align: right;
      padding-right: 12px;
      color: #999;
      font-weight: normal;
    }

    #query-container {
      max-width: 600px;
      border: 1px solid #999;
      border-radius: 0.25rem;
      margin: 20px auto;
      padding: 10px;
    }

    .other-rank {
      font-size: 1.2em;
      display: inline-block;
      width: 20px;
      margin-top: 46px;
      margin-left: 3px;
      margin-right: 3px;
      cursor: help;
    }

    mark {
      padding: 0;
      font-weight: bold;
    }

    .snippet {
      font-size: 0.9em;
      line-height: 1.2;
    }

    .elip {
      text-align: center;
      margin: 16px;
      color: gray;
    }

    .doc-info {
      white-space: nowrap;
    }

    .card-header {
      min-height: 128px;
      cursor: pointer;
    }

    .swatch {
      display: inline-block;
      width: 16px;
      height: 16px;
      vertical-align: middle;
    }

    .form-group {
      width: 150px;
      height: 20px;
      padding-left: 10px;
      padding-top: 10px;
    }

    .nobackground {
      background: transparent !important;
      font-weight: normal;
    }
    .styled-table {
      margin-left: 0px;
      margin-top: 10px;
      border-collapse: collapse;    
      font-size: 0.9em;
      /* font-family: sans-serif;       */
      min-width: 350px;      
      box-shadow: 0 0 20px rgba(0, 0, 0, 0.15);
    }
    .styled-table thead tr {
      background-color: #17a2b8;
      color: #ffffff;
      text-align: left;
    }    
    /* .styled-table th, */
    .styled-table td {
      /* padding: 12px 15px; */
      text-align: center;
    }    
    .styled-table tbody tr {
      color: #ffffff;
    }
    /*
    .styled-table tbody tr:nth-of-type(even) {
      background-color: #f3f3f3;
    } */

    .styled-table tbody tr:last-of-type {
      border-bottom: 2px solid #009879;
    }

    #ranking-summary ul li span {
      margin-right: 5px;
    }    
  </style>
</head>

<body>
  <header>
    <div class="collapse bg-dark" id="navbarHeader">
      <div class="container">
        <div class="row">
          <div class="col-sm-6 col-md-6 py-4">
            <h6 class="text-white">Summary</h6>
            <p class="text-white" id="ranking-summary"></p>
          </div>
          <div class="col-sm-5 col-md-5 py-4"> 
            <h6 class="text-white">Ranking statistics</h6>                                   
            <ul>
              <li class="text-white"><span id="contrast-measure"></span></li>
              <li class="text-white"> <span>Relevance metrics</span> <div id="metrics"></div></li>
            </ul>                        
          </div>
        </div>
      </div>
    </div>
    <div class="navbar navbar-dark bg-dark box-shadow navbar-fixed-top">
      <div class="container d-flex justify-content-between">
        <a href="#" class="navbar-brand d-flex align-items-center">
          <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-search"
            viewBox="0 0 16 16">
            <path
              d="M11.742 10.344a6.5 6.5 0 1 0-1.397 1.398h-.001c.03.04.062.078.098.115l3.85 3.85a1 1 0 0 0 1.415-1.414l-3.85-3.85a1.007 1.007 0 0 0-.115-.1zM12 6.5a5.5 5.5 0 1 1-11 0 5.5 5.5 0 0 1 11 0z" />
          </svg>
          <strong style="padding-left:  5px;">DiffIR</strong>
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarHeader"
          aria-controls="navbarHeader" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
      </div>
    </div>
  </header>
  <div class="container">
    <div class="input-group" style="padding-top: 50px; padding-bottom: 10px; background-color: white;">
      <select id="Queries" data-width="100%" data-style="border" data-container="body"></select>
    </div>
    <div id="query-container" class="sticky-top" style="background-color: white;">
      <div style="position:relative">
        <button id="query-collapse-btn" style="position: absolute; top: 12px; right: 8px;" type="button"
          class="btn btn-outline-info btn-sm" data-toggle="collapse" data-target=".query_collapse" aria-expanded="false"
          aria-controls="query_collapse">
          <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor"
            class="bi bi-arrows-angle-expand" viewBox="0 0 16 16">
            <path fill-rule="evenodd"
              d="M5.828 10.172a.5.5 0 0 0-.707 0l-4.096 4.096V11.5a.5.5 0 0 0-1 0v3.975a.5.5 0 0 0 .5.5H4.5a.5.5 0 0 0 0-1H1.732l4.096-4.096a.5.5 0 0 0 0-.707zm4.344-4.344a.5.5 0 0 0 .707 0l4.096-4.096V4.5a.5.5 0 1 0 1 0V.525a.5.5 0 0 0-.5-.5H11.5a.5.5 0 0 0 0 1h2.768l-4.096 4.096a.5.5 0 0 0 0 .707z" />
          </svg>
        </button>
      </div>
      <div id="Query" style="padding-right: 45px;">
      </div>
    </div>
    <div class="row justify-content-center" id="runName">
      <div class="col">
        <h6 id="Run1Name" style="text-align: center;"></h6>
      </div>
      <div class="col">
        <h6 id="Run2Name" style="text-align: center;"></h6>
      </div>
    </div>
    <div class="row" id="docList">
      <div id="Run1Docs" class="col">
      </div>
      <div id="Run2Docs" class="col">
      </div>
    </div>    
  </div>
  <!-- Optional JavaScript -->
  <!-- jQuery first, then Popper.js, then Bootstrap JS -->
  <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"
    integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo"
    crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js"
    integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1"
    crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"
    integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM"
    crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap-select@1.13.14/dist/js/bootstrap-select.min.js"></script>
  <script type="text/javascript">
    var data = {"meta": {"run1_name": "/tira-data/output/run.txt", "run2_name": null, "dataset": "iranthology-memory", "measure": "topk", "qrelDefs": {"0": "Not Relevant", "1": "Relevant"}, "queryFields": ["query_id", "title", "description", "narrative"], "docFields": ["doc_id", "abstract", "title", "authors", "year", "booktitle"], "relevanceColors": {"null": "#888888"}}, "queries": [{"fields": {"query_id": "1", "title": "Deep Neural Networks", "description": "Which papers talk about Deep Neural Networks?", "narrative": "Relevant papers have at least one mention of Deep Neural. Paper containing only Deep or Neural are not relevant.", "contrast": {"name": "singlerun", "value": 0}}, "metrics": {"P@1": [null], "P@3": [null], "P@5": [null], "P@10": [null], "nDCG@1": [null], "nDCG@3": [null], "nDCG@5": [null], "nDCG@10": [null]}, "run_1": [{"doc_id": "2017.cikm_conference-2017.312", "score": 23.09914223492266, "relevance": null, "rank": 1, "weights": {"doc_id": [], "default_text": [[15, 19, 1.0], [20, 26, 1.0], [27, 35, 1.0], [216, 220, 1.0], [221, 227, 1.0], [228, 236, 1.0], [426, 430, 1.0], [431, 437, 1.0], [438, 446, 1.0], [688, 692, 1.0], [693, 699, 1.0], [700, 708, 1.0], [755, 761, 1.0], [762, 770, 1.0], [772, 776, 1.0], [807, 813, 1.0], [930, 934, 1.0], [935, 941, 1.0], [942, 950, 1.0]]}, "snippet": {"field": "default_text", "start": 683, "stop": 883, "weights": [[5, 9, 1.0], [10, 16, 1.0], [17, 25, 1.0], [72, 78, 1.0], [79, 87, 1.0], [89, 93, 1.0], [124, 130, 1.0]]}}, {"doc_id": "2020.wsdm_conference-2020.4", "score": 22.204831039400077, "relevance": null, "rank": 2, "weights": {"doc_id": [], "default_text": [[4, 8, 1.0], [26, 32, 1.0], [33, 41, 1.0], [53, 57, 1.0], [107, 111, 1.0], [112, 118, 1.0], [119, 127, 1.0], [184, 188, 1.0], [213, 217, 1.0], [264, 270, 1.0], [271, 279, 1.0], [360, 364, 1.0]]}, "snippet": {"field": "default_text", "start": 0, "stop": 200, "weights": [[4, 8, 1.0], [26, 32, 1.0], [33, 41, 1.0], [53, 57, 1.0], [107, 111, 1.0], [112, 118, 1.0], [119, 127, 1.0], [184, 188, 1.0]]}}, {"doc_id": "2020.wsdm_conference-2020.126", "score": 21.784120067185242, "relevance": null, "rank": 3, "weights": {"doc_id": [], "default_text": [[21, 25, 1.0], [26, 32, 1.0], [33, 41, 1.0], [165, 169, 1.0], [170, 176, 1.0], [177, 185, 1.0], [269, 273, 1.0], [587, 591, 1.0], [592, 598, 1.0], [599, 607, 1.0], [844, 848, 1.0], [849, 855, 1.0], [856, 864, 1.0], [954, 958, 1.0], [959, 965, 1.0], [1162, 1166, 1.0], [1216, 1222, 1.0], [1223, 1231, 1.0]]}, "snippet": {"field": "default_text", "start": 16, "stop": 216, "weights": [[5, 9, 1.0], [10, 16, 1.0], [17, 25, 1.0], [149, 153, 1.0], [154, 160, 1.0], [161, 169, 1.0]]}}, {"doc_id": "2018.ijmir_journal-ir0anthology0volumeA7A1.1", "score": 21.565785571060943, "relevance": null, "rank": 4, "weights": {"doc_id": [], "default_text": [[25, 29, 1.0], [30, 36, 1.0], [37, 45, 1.0]]}, "snippet": {"field": "default_text", "start": 20, "stop": 220, "weights": [[5, 9, 1.0], [10, 16, 1.0], [17, 25, 1.0]]}}, {"doc_id": "2017.mir_conference-2017.38", "score": 21.565785571060943, "relevance": null, "rank": 5, "weights": {"doc_id": [], "default_text": [[26, 30, 1.0], [31, 37, 1.0], [38, 46, 1.0]]}, "snippet": {"field": "default_text", "start": 21, "stop": 221, "weights": [[5, 9, 1.0], [10, 16, 1.0], [17, 25, 1.0]]}}, {"doc_id": "2015.mir_conference-2015.49", "score": 21.565785571060943, "relevance": null, "rank": 6, "weights": {"doc_id": [], "default_text": [[2, 6, 1.0], [7, 13, 1.0]]}, "snippet": {"field": "default_text", "start": 0, "stop": 200, "weights": [[2, 6, 1.0], [7, 13, 1.0]]}}, {"doc_id": "2020.wwwconf_conference-2020c.107", "score": 21.29220477456937, "relevance": null, "rank": 7, "weights": {"doc_id": [], "default_text": [[40, 44, 1.0], [45, 51, 1.0], [52, 60, 1.0]]}, "snippet": {"field": "default_text", "start": 35, "stop": 235, "weights": [[5, 9, 1.0], [10, 16, 1.0], [17, 25, 1.0]]}}, {"doc_id": "2020.tweb_journal-ir0anthology0volumeA14A2.2", "score": 21.025478247652224, "relevance": null, "rank": 8, "weights": {"doc_id": [], "default_text": [[31, 35, 1.0], [36, 42, 1.0], [43, 51, 1.0]]}, "snippet": {"field": "default_text", "start": 26, "stop": 226, "weights": [[5, 9, 1.0], [10, 16, 1.0], [17, 25, 1.0]]}}, {"doc_id": "2019.cikm_conference-2019.187", "score": 21.025478247652224, "relevance": null, "rank": 9, "weights": {"doc_id": [], "default_text": [[41, 45, 1.0], [46, 52, 1.0]]}, "snippet": {"field": "default_text", "start": 36, "stop": 236, "weights": [[5, 9, 1.0], [10, 16, 1.0]]}}, {"doc_id": "2018.tois_journal-ir0anthology0volumeA36A4.4", "score": 21.025478247652224, "relevance": null, "rank": 10, "weights": {"doc_id": [], "default_text": [[53, 57, 1.0], [58, 64, 1.0], [65, 73, 1.0]]}, "snippet": {"field": "default_text", "start": 48, "stop": 248, "weights": [[5, 9, 1.0], [10, 16, 1.0], [17, 25, 1.0]]}}], "run_2": [], "summary": [["10 unjudged doc(s) move to a top spot in the ranking"]], "mergedWeights": {}}, {"fields": {"query_id": "2", "title": "Information Retrieval", "description": "Which papers talk about Information Retrieval?", "narrative": "Relevant paper have at least one mention of Information Retrieval. Paper containing only Information or Retrieval are not relevant.", "contrast": {"name": "singlerun", "value": 0}}, "metrics": {"P@1": [null], "P@3": [null], "P@5": [null], "P@10": [null], "nDCG@1": [null], "nDCG@3": [null], "nDCG@5": [null], "nDCG@10": [null]}, "run_1": [{"doc_id": "2003.sigirconf_conference-2003.73", "score": 3.794061913322113, "relevance": null, "rank": 1, "weights": {"doc_id": [], "default_text": [[4, 13, 1.0], [85, 96, 1.0], [97, 106, 1.0], [115, 124, 1.0], [140, 149, 1.0], [182, 191, 1.0], [238, 247, 1.0], [319, 328, 1.0], [506, 515, 1.0], [663, 672, 1.0]]}, "snippet": {"field": "default_text", "start": 0, "stop": 200, "weights": [[4, 13, 1.0], [85, 96, 1.0], [97, 106, 1.0], [115, 124, 1.0], [140, 149, 1.0], [182, 191, 1.0]]}}, {"doc_id": "2015.ictir_conference-2015.2", "score": 3.6996110607073303, "relevance": null, "rank": 2, "weights": {"doc_id": [], "default_text": [[10, 19, 1.0], [43, 54, 1.0], [168, 179, 1.0], [180, 189, 1.0], [668, 677, 1.0]]}, "snippet": {"field": "default_text", "start": 5, "stop": 205, "weights": [[5, 14, 1.0], [38, 49, 1.0], [163, 174, 1.0], [175, 184, 1.0]]}}, {"doc_id": "2011.tois_journal-ir0anthology0volumeA29A2.0", "score": 3.6672090176983567, "relevance": null, "rank": 3, "weights": {"doc_id": [], "default_text": [[25, 36, 1.0], [37, 46, 1.0], [75, 84, 1.0], [132, 143, 1.0], [144, 153, 1.0], [269, 278, 1.0], [444, 453, 1.0], [599, 608, 1.0], [662, 671, 1.0], [729, 738, 1.0], [782, 791, 1.0], [851, 860, 1.0], [893, 902, 1.0], [1049, 1058, 1.0], [1212, 1221, 1.0], [1242, 1251, 1.0], [1377, 1386, 1.0], [1418, 1427, 1.0]]}, "snippet": {"field": "default_text", "start": 20, "stop": 220, "weights": [[5, 16, 1.0], [17, 26, 1.0], [55, 64, 1.0], [112, 123, 1.0], [124, 133, 1.0]]}}, {"doc_id": "2006.ipm_journal-ir0anthology0volumeA42A1.2", "score": 3.619692141835906, "relevance": null, "rank": 4, "weights": {"doc_id": [], "default_text": [[34, 45, 1.0], [46, 55, 1.0], [100, 111, 1.0], [112, 121, 1.0], [145, 154, 1.0], [363, 372, 1.0], [462, 471, 1.0], [525, 534, 1.0], [605, 614, 1.0], [635, 644, 1.0], [665, 674, 1.0], [822, 831, 1.0]]}, "snippet": {"field": "default_text", "start": 29, "stop": 229, "weights": [[5, 16, 1.0], [17, 26, 1.0], [71, 82, 1.0], [83, 92, 1.0], [116, 125, 1.0]]}}, {"doc_id": "2012.sigirjournals_journal-ir0anthology0volumeA46A1.9", "score": 3.6185346786942922, "relevance": null, "rank": 5, "weights": {"doc_id": [], "default_text": [[11, 20, 1.0], [159, 170, 1.0], [171, 180, 1.0], [476, 485, 1.0], [528, 539, 1.0], [610, 619, 1.0], [749, 758, 1.0], [844, 853, 1.0], [872, 881, 1.0], [977, 988, 1.0], [1784, 1793, 1.0], [1823, 1832, 1.0], [1879, 1888, 1.0], [2021, 2030, 1.0], [2162, 2171, 1.0], [2464, 2473, 1.0], [2514, 2523, 1.0], [2579, 2590, 1.0], [2636, 2647, 1.0]]}, "snippet": {"field": "default_text", "start": 2459, "stop": 2659, "weights": [[5, 14, 1.0], [55, 64, 1.0], [120, 131, 1.0], [177, 188, 1.0]]}}, {"doc_id": "2008.sigirconf_conference-2008.170", "score": 3.61518918464814, "relevance": null, "rank": 6, "weights": {"doc_id": [], "default_text": [[73, 82, 1.0], [137, 146, 1.0], [193, 202, 1.0], [338, 347, 1.0], [470, 479, 1.0], [502, 511, 1.0]]}, "snippet": {"field": "default_text", "start": 68, "stop": 268, "weights": [[5, 14, 1.0], [69, 78, 1.0], [125, 134, 1.0]]}}, {"doc_id": "2005.sigirconf_conference-2005.64", "score": 3.610666246118416, "relevance": null, "rank": 7, "weights": {"doc_id": [], "default_text": [[42, 53, 1.0], [54, 63, 1.0], [81, 90, 1.0], [147, 156, 1.0], [338, 347, 1.0], [563, 572, 1.0], [634, 643, 1.0], [766, 775, 1.0], [831, 840, 1.0], [908, 917, 1.0], [955, 964, 1.0], [1047, 1056, 1.0], [1120, 1129, 1.0], [1160, 1169, 1.0], [1226, 1235, 1.0], [1321, 1330, 1.0]]}, "snippet": {"field": "default_text", "start": 37, "stop": 237, "weights": [[5, 16, 1.0], [17, 26, 1.0], [44, 53, 1.0], [110, 119, 1.0]]}}, {"doc_id": "2013.sigirconf_conference-2013.125", "score": 3.6099206633998313, "relevance": null, "rank": 8, "weights": {"doc_id": [], "default_text": [[111, 122, 1.0], [123, 132, 1.0], [228, 237, 1.0], [447, 456, 1.0], [475, 484, 1.0], [501, 510, 1.0], [970, 979, 1.0], [1004, 1013, 1.0]]}, "snippet": {"field": "default_text", "start": 106, "stop": 306, "weights": [[5, 16, 1.0], [17, 26, 1.0], [122, 131, 1.0]]}}, {"doc_id": "2002.ntcir_workshop-2002.59", "score": 3.6080580530471744, "relevance": null, "rank": 9, "weights": {"doc_id": [], "default_text": [[31, 40, 1.0], [53, 62, 1.0], [103, 112, 1.0], [213, 222, 1.0], [259, 268, 1.0], [436, 445, 1.0], [486, 495, 1.0], [572, 581, 1.0]]}, "snippet": {"field": "default_text", "start": 26, "stop": 226, "weights": [[5, 14, 1.0], [27, 36, 1.0], [77, 86, 1.0], [187, 196, 1.0]]}}, {"doc_id": "1981.sigirconf_conference-81.7", "score": 3.6061973638049842, "relevance": null, "rank": 10, "weights": {"doc_id": [], "default_text": [[29, 38, 1.0], [95, 104, 1.0], [192, 201, 1.0], [288, 297, 1.0], [386, 395, 1.0], [425, 434, 1.0]]}, "snippet": {"field": "default_text", "start": 24, "stop": 224, "weights": [[5, 14, 1.0], [71, 80, 1.0], [168, 177, 1.0]]}}], "run_2": [], "summary": [["10 unjudged doc(s) move to a top spot in the ranking"]], "mergedWeights": {}}, {"fields": {"query_id": "3", "title": "Analysis for Android apps", "description": "Which papers talk about the analysis of android apps?", "narrative": "Relevant papers talk at least in one line about android apps. Paper containing only apps are not relevant.", "contrast": {"name": "singlerun", "value": 0}}, "metrics": {"P@1": [null], "P@3": [null], "P@5": [null], "P@10": [null], "nDCG@1": [null], "nDCG@3": [null], "nDCG@5": [null], "nDCG@10": [null]}, "run_1": [{"doc_id": "2020.tweb_journal-ir0anthology0volumeA14A3.4", "score": 34.607574339576544, "relevance": null, "rank": 1, "weights": {"doc_id": [], "default_text": [[49, 57, 1.0], [85, 92, 1.0], [93, 97, 1.0]]}, "snippet": {"field": "default_text", "start": 44, "stop": 244, "weights": [[5, 13, 1.0], [41, 48, 1.0], [49, 53, 1.0]]}}, {"doc_id": "2017.wwwconf_conference-2017.20", "score": 28.519157715707927, "relevance": null, "rank": 2, "weights": {"doc_id": [], "default_text": [[252, 256, 1.0], [450, 457, 1.0], [458, 462, 1.0], [520, 527, 1.0], [570, 578, 1.0], [705, 709, 1.0], [781, 785, 1.0], [936, 940, 1.0], [995, 999, 1.0], [1118, 1122, 1.0]]}, "snippet": {"field": "default_text", "start": 445, "stop": 645, "weights": [[5, 12, 1.0], [13, 17, 1.0], [75, 82, 1.0], [125, 133, 1.0]]}}, {"doc_id": "2020.wwwconf_conference-2020.154", "score": 28.258806833170933, "relevance": null, "rank": 3, "weights": {"doc_id": [], "default_text": [[63, 70, 1.0], [71, 75, 1.0]]}, "snippet": {"field": "default_text", "start": 58, "stop": 258, "weights": [[5, 12, 1.0], [13, 17, 1.0]]}}, {"doc_id": "2018.wwwconf_conference-2018.144", "score": 28.251419616525666, "relevance": null, "rank": 4, "weights": {"doc_id": [], "default_text": [[49, 56, 1.0], [642, 649, 1.0], [650, 654, 1.0], [757, 761, 1.0], [1131, 1135, 1.0], [1211, 1219, 1.0], [1236, 1244, 1.0], [1417, 1421, 1.0], [1585, 1592, 1.0], [1593, 1597, 1.0], [1607, 1615, 1.0]]}, "snippet": {"field": "default_text", "start": 1412, "stop": 1612, "weights": [[5, 9, 1.0], [173, 180, 1.0], [181, 185, 1.0], [195, 203, 1.0]]}}, {"doc_id": "2019.wwwconf_conference-2019.152", "score": 27.913462218099355, "relevance": null, "rank": 5, "weights": {"doc_id": [], "default_text": [[24, 31, 1.0]]}, "snippet": {"field": "default_text", "start": 19, "stop": 219, "weights": [[5, 12, 1.0]]}}, {"doc_id": "2021.wwwconf_conference-2021.128", "score": 27.576456455755135, "relevance": null, "rank": 6, "weights": {"doc_id": [], "default_text": [[76, 83, 1.0]]}, "snippet": {"field": "default_text", "start": 71, "stop": 271, "weights": [[5, 12, 1.0]]}}, {"doc_id": "2014.wwwconf_conference-2014.21", "score": 26.811743842327147, "relevance": null, "rank": 7, "weights": {"doc_id": [], "default_text": [[351, 358, 1.0], [691, 695, 1.0], [974, 982, 1.0], [1113, 1120, 1.0], [1267, 1274, 1.0], [1297, 1301, 1.0]]}, "snippet": {"field": "default_text", "start": 1108, "stop": 1308, "weights": [[5, 12, 1.0], [159, 166, 1.0], [189, 193, 1.0]]}}, {"doc_id": "2018.wwwjournals_journal-ir0anthology0volumeA21A1.5", "score": 26.704832013548796, "relevance": null, "rank": 8, "weights": {"doc_id": [], "default_text": [[30, 37, 1.0], [76, 84, 1.0], [102, 109, 1.0], [294, 298, 1.0], [401, 405, 1.0], [558, 562, 1.0], [691, 695, 1.0], [764, 768, 1.0], [1052, 1056, 1.0], [1174, 1178, 1.0], [1213, 1217, 1.0], [1316, 1320, 1.0], [1794, 1801, 1.0], [1802, 1806, 1.0]]}, "snippet": {"field": "default_text", "start": 25, "stop": 225, "weights": [[5, 12, 1.0], [51, 59, 1.0], [77, 84, 1.0]]}}, {"doc_id": "2018.wwwjournals_journal-ir0anthology0volumeA21A1.6", "score": 25.925077517658714, "relevance": null, "rank": 9, "weights": {"doc_id": [], "default_text": [[75, 82, 1.0], [94, 98, 1.0], [145, 149, 1.0], [173, 180, 1.0], [260, 264, 1.0], [614, 618, 1.0], [891, 895, 1.0], [954, 962, 1.0], [975, 983, 1.0], [1152, 1156, 1.0], [1520, 1524, 1.0], [1591, 1595, 1.0], [1664, 1672, 1.0], [1686, 1694, 1.0], [1729, 1733, 1.0]]}, "snippet": {"field": "default_text", "start": 70, "stop": 270, "weights": [[5, 12, 1.0], [24, 28, 1.0], [75, 79, 1.0], [103, 110, 1.0], [190, 194, 1.0]]}}, {"doc_id": "2016.wwwconf_conference-2016.119", "score": 25.51219251302127, "relevance": null, "rank": 10, "weights": {"doc_id": [], "default_text": [[172, 176, 1.0], [225, 232, 1.0], [278, 282, 1.0], [382, 386, 1.0], [524, 528, 1.0], [804, 811, 1.0], [981, 985, 1.0], [1072, 1076, 1.0], [1136, 1140, 1.0]]}, "snippet": {"field": "default_text", "start": 167, "stop": 367, "weights": [[5, 9, 1.0], [58, 65, 1.0], [111, 115, 1.0]]}}], "run_2": [], "summary": [["10 unjudged doc(s) move to a top spot in the ranking"]], "mergedWeights": {}}, {"fields": {"query_id": "4", "title": "The University of Amsterdam", "description": "Which papers are created by the University of Amsterdam?", "narrative": "Relevant papers are created or at least co-written by the University of Amsterdam. Paper containing only\n      University not relevant.", "contrast": {"name": "singlerun", "value": 0}}, "metrics": {"P@1": [null], "P@3": [null], "P@5": [null], "P@10": [null], "nDCG@1": [null], "nDCG@3": [null], "nDCG@5": [null], "nDCG@10": [null]}, "run_1": [{"doc_id": "2011.trec_conference-2011.102", "score": 25.20156596065881, "relevance": null, "rank": 1, "weights": {"doc_id": [], "default_text": [[4, 14, 1.0], [18, 27, 1.0], [96, 106, 1.0], [110, 119, 1.0]]}, "snippet": {"field": "default_text", "start": 0, "stop": 200, "weights": [[4, 14, 1.0], [18, 27, 1.0], [96, 106, 1.0], [110, 119, 1.0]]}}, {"doc_id": "2012.trec_conference-2012.73", "score": 25.027581197772207, "relevance": null, "rank": 2, "weights": {"doc_id": [], "default_text": [[4, 14, 1.0], [18, 27, 1.0], [78, 88, 1.0], [92, 101, 1.0]]}, "snippet": {"field": "default_text", "start": 0, "stop": 200, "weights": [[4, 14, 1.0], [18, 27, 1.0], [78, 88, 1.0], [92, 101, 1.0]]}}, {"doc_id": "2005.clef_workshop-2005w.97", "score": 24.68672037995953, "relevance": null, "rank": 3, "weights": {"doc_id": [], "default_text": [[4, 14, 1.0], [18, 27, 1.0], [60, 70, 1.0], [74, 83, 1.0]]}, "snippet": {"field": "default_text", "start": 0, "stop": 200, "weights": [[4, 14, 1.0], [18, 27, 1.0], [60, 70, 1.0], [74, 83, 1.0]]}}, {"doc_id": "2006.clef_workshop-2006w.110", "score": 23.290036579983884, "relevance": null, "rank": 4, "weights": {"doc_id": [], "default_text": [[4, 14, 1.0], [18, 27, 1.0]]}, "snippet": {"field": "default_text", "start": 0, "stop": 200, "weights": [[4, 14, 1.0], [18, 27, 1.0]]}}, {"doc_id": "2009.clef_workshop-20092.32", "score": 22.70653002117305, "relevance": null, "rank": 5, "weights": {"doc_id": [], "default_text": [[4, 14, 1.0], [18, 27, 1.0]]}, "snippet": {"field": "default_text", "start": 0, "stop": 200, "weights": [[4, 14, 1.0], [18, 27, 1.0]]}}, {"doc_id": "2010.trec_conference-2010.51", "score": 22.425605433298436, "relevance": null, "rank": 6, "weights": {"doc_id": [], "default_text": [[4, 14, 1.0], [18, 27, 1.0]]}, "snippet": {"field": "default_text", "start": 0, "stop": 200, "weights": [[4, 14, 1.0], [18, 27, 1.0]]}}, {"doc_id": "2007.clef_workshop-2007.43", "score": 22.425605433298436, "relevance": null, "rank": 7, "weights": {"doc_id": [], "default_text": [[4, 14, 1.0], [18, 27, 1.0]]}, "snippet": {"field": "default_text", "start": 0, "stop": 200, "weights": [[4, 14, 1.0], [18, 27, 1.0]]}}, {"doc_id": "2007.clef_workshop-2007w.112", "score": 21.99116118321059, "relevance": null, "rank": 8, "weights": {"doc_id": [], "default_text": [[4, 14, 1.0], [18, 27, 1.0], [128, 138, 1.0], [142, 151, 1.0]]}, "snippet": {"field": "default_text", "start": 0, "stop": 200, "weights": [[4, 14, 1.0], [18, 27, 1.0], [128, 138, 1.0], [142, 151, 1.0]]}}, {"doc_id": "2013.trec_conference-2013.23", "score": 21.623046170176366, "relevance": null, "rank": 9, "weights": {"doc_id": [], "default_text": [[55, 65, 1.0], [69, 78, 1.0]]}, "snippet": {"field": "default_text", "start": 50, "stop": 250, "weights": [[5, 15, 1.0], [19, 28, 1.0]]}}, {"doc_id": "2010.clef_workshop-2010w.104", "score": 21.09538706705811, "relevance": null, "rank": 10, "weights": {"doc_id": [], "default_text": [[4, 14, 1.0], [18, 27, 1.0], [94, 104, 1.0], [108, 117, 1.0]]}, "snippet": {"field": "default_text", "start": 0, "stop": 200, "weights": [[4, 14, 1.0], [18, 27, 1.0], [94, 104, 1.0], [108, 117, 1.0]]}}], "run_2": [], "summary": [["10 unjudged doc(s) move to a top spot in the ranking"]], "mergedWeights": {}}, {"fields": {"query_id": "5", "title": "Neural Ranking for eCommerce Product Search", "description": "Which paper is about Ranking Product Search and its applications in eCommerce?", "narrative": "Relevant papers that addresses application of Task Models and Textual Embeddings in the field of electronic\n      commerce. Not relevant are papers showcasing applications that do not contain the topic eCommerce.", "contrast": {"name": "singlerun", "value": 0}}, "metrics": {"P@1": [null], "P@3": [null], "P@5": [null], "P@10": [null], "nDCG@1": [null], "nDCG@3": [null], "nDCG@5": [null], "nDCG@10": [null]}, "run_1": [{"doc_id": "2018.sigirconf_workshop-2018ecom.14", "score": 39.549210278312785, "relevance": null, "rank": 1, "weights": {"doc_id": [], "default_text": [[11, 17, 1.0], [18, 25, 1.0], [30, 39, 1.0], [40, 47, 1.0], [48, 54, 1.0], [131, 137, 1.0], [138, 145, 1.0], [150, 159, 1.0], [160, 167, 1.0], [168, 174, 1.0], [270, 279, 1.0]]}, "snippet": {"field": "default_text", "start": 6, "stop": 206, "weights": [[5, 11, 1.0], [12, 19, 1.0], [24, 33, 1.0], [34, 41, 1.0], [42, 48, 1.0], [125, 131, 1.0], [132, 139, 1.0], [144, 153, 1.0], [154, 161, 1.0], [162, 168, 1.0]]}}, {"doc_id": "2011.sigirconf_conference-2011.10", "score": 26.027833381277468, "relevance": null, "rank": 2, "weights": {"doc_id": [], "default_text": [[29, 38, 1.0], [95, 101, 1.0], [106, 115, 1.0], [117, 124, 1.0], [126, 132, 1.0], [154, 161, 1.0], [277, 284, 1.0], [354, 361, 1.0], [362, 368, 1.0], [462, 468, 1.0], [664, 673, 1.0], [674, 680, 1.0], [710, 719, 1.0]]}, "snippet": {"field": "default_text", "start": 24, "stop": 224, "weights": [[5, 14, 1.0], [71, 77, 1.0], [82, 91, 1.0], [93, 100, 1.0], [102, 108, 1.0], [130, 137, 1.0]]}}, {"doc_id": "2019.wwwconf_conference-2019.217", "score": 24.063394653347586, "relevance": null, "rank": 3, "weights": {"doc_id": [], "default_text": [[0, 6, 1.0], [35, 42, 1.0], [53, 60, 1.0], [61, 67, 1.0]]}, "snippet": {"field": "default_text", "start": 0, "stop": 200, "weights": [[0, 6, 1.0], [35, 42, 1.0], [53, 60, 1.0], [61, 67, 1.0]]}}, {"doc_id": "2019.sigirconf_workshop-2019ecom.19", "score": 23.366938307511568, "relevance": null, "rank": 4, "weights": {"doc_id": [], "default_text": [[0, 7, 1.0], [23, 30, 1.0], [64, 70, 1.0], [86, 95, 1.0], [341, 347, 1.0], [525, 531, 1.0], [675, 682, 1.0], [694, 700, 1.0]]}, "snippet": {"field": "default_text", "start": 0, "stop": 200, "weights": [[0, 7, 1.0], [23, 30, 1.0], [64, 70, 1.0], [86, 95, 1.0]]}}, {"doc_id": "2017.sigirconf_conference-2017.251", "score": 22.771917775472012, "relevance": null, "rank": 5, "weights": {"doc_id": [], "default_text": [[23, 32, 1.0], [501, 510, 1.0], [651, 660, 1.0], [735, 744, 1.0], [745, 751, 1.0], [890, 899, 1.0], [984, 990, 1.0], [1048, 1054, 1.0], [1128, 1134, 1.0]]}, "snippet": {"field": "default_text", "start": 646, "stop": 846, "weights": [[5, 14, 1.0], [89, 98, 1.0], [99, 105, 1.0]]}}, {"doc_id": "2019.spire_conference-2019.4", "score": 22.723147219036054, "relevance": null, "rank": 6, "weights": {"doc_id": [], "default_text": [[58, 67, 1.0], [68, 74, 1.0]]}, "snippet": {"field": "default_text", "start": 53, "stop": 253, "weights": [[5, 14, 1.0], [15, 21, 1.0]]}}, {"doc_id": "2018.sigirconf_conference-2018.230", "score": 22.087873226477157, "relevance": null, "rank": 7, "weights": {"doc_id": [], "default_text": [[23, 32, 1.0], [521, 530, 1.0], [670, 679, 1.0], [754, 763, 1.0], [764, 770, 1.0], [909, 918, 1.0], [1003, 1009, 1.0], [1067, 1073, 1.0], [1147, 1153, 1.0], [1379, 1388, 1.0]]}, "snippet": {"field": "default_text", "start": 665, "stop": 865, "weights": [[5, 14, 1.0], [89, 98, 1.0], [99, 105, 1.0]]}}, {"doc_id": "2011.wwwconf_workshop-2011ldow.14", "score": 20.888409760605466, "relevance": null, "rank": 8, "weights": {"doc_id": [], "default_text": [[220, 229, 1.0], [264, 271, 1.0], [636, 643, 1.0], [941, 950, 1.0], [1011, 1017, 1.0], [1062, 1069, 1.0], [1085, 1092, 1.0], [1166, 1175, 1.0]]}, "snippet": {"field": "default_text", "start": 936, "stop": 1136, "weights": [[5, 14, 1.0], [75, 81, 1.0], [126, 133, 1.0], [149, 156, 1.0]]}}, {"doc_id": "2018.sigirconf_workshop-2018ecom.5", "score": 20.643138918844606, "relevance": null, "rank": 9, "weights": {"doc_id": [], "default_text": [[155, 164, 1.0], [171, 178, 1.0], [240, 246, 1.0], [267, 274, 1.0]]}, "snippet": {"field": "default_text", "start": 150, "stop": 350, "weights": [[5, 14, 1.0], [21, 28, 1.0], [90, 96, 1.0], [117, 124, 1.0]]}}, {"doc_id": "2006.ipm_journal-ir0anthology0volumeA42A4.12", "score": 20.12853455763284, "relevance": null, "rank": 10, "weights": {"doc_id": [], "default_text": [[25, 31, 1.0], [64, 73, 1.0], [313, 322, 1.0], [397, 406, 1.0], [545, 551, 1.0], [589, 598, 1.0], [670, 676, 1.0], [700, 709, 1.0], [755, 764, 1.0], [830, 839, 1.0], [860, 866, 1.0], [958, 967, 1.0], [968, 974, 1.0], [1193, 1202, 1.0]]}, "snippet": {"field": "default_text", "start": 665, "stop": 865, "weights": [[5, 11, 1.0], [35, 44, 1.0], [90, 99, 1.0], [165, 174, 1.0], [195, 201, 1.0]]}}], "run_2": [], "summary": [["10 unjudged doc(s) move to a top spot in the ranking"]], "mergedWeights": {}}, {"fields": {"query_id": "6", "title": "web pages evolution", "description": "Which paper is about the evolution of web pages?", "narrative": "Relevant paper have at least one mention of web evolution. Paper containing only web page or evolution are not relevant.", "contrast": {"name": "singlerun", "value": 0}}, "metrics": {"P@1": [null], "P@3": [null], "P@5": [null], "P@10": [null], "nDCG@1": [null], "nDCG@3": [null], "nDCG@5": [null], "nDCG@10": [null]}, "run_1": [{"doc_id": "2005.wwwconf_workshop-2004webdyn.11", "score": 22.10585691154151, "relevance": null, "rank": 1, "weights": {"doc_id": [], "default_text": [[52, 61, 1.0], [73, 76, 1.0], [77, 82, 1.0], [137, 146, 1.0], [154, 157, 1.0], [292, 295, 1.0], [317, 320, 1.0], [321, 326, 1.0], [393, 402, 1.0], [513, 518, 1.0], [629, 634, 1.0], [741, 744, 1.0]]}, "snippet": {"field": "default_text", "start": 47, "stop": 247, "weights": [[5, 14, 1.0], [26, 29, 1.0], [30, 35, 1.0], [90, 99, 1.0], [107, 110, 1.0]]}}, {"doc_id": "2008.wwwconf_conference-2008.169", "score": 19.985960495455586, "relevance": null, "rank": 2, "weights": {"doc_id": [], "default_text": [[11, 20, 1.0], [24, 27, 1.0], [28, 33, 1.0], [85, 88, 1.0], [89, 94, 1.0], [274, 279, 1.0], [329, 332, 1.0]]}, "snippet": {"field": "default_text", "start": 6, "stop": 206, "weights": [[5, 14, 1.0], [18, 21, 1.0], [22, 27, 1.0], [79, 82, 1.0], [83, 88, 1.0]]}}, {"doc_id": "2016.wsdm_conference-2016.14", "score": 19.534565433085564, "relevance": null, "rank": 3, "weights": {"doc_id": [], "default_text": [[63, 66, 1.0], [186, 189, 1.0], [389, 392, 1.0], [393, 398, 1.0], [756, 759, 1.0], [776, 785, 1.0], [828, 831, 1.0], [832, 837, 1.0], [915, 918, 1.0], [919, 924, 1.0], [1049, 1052, 1.0], [1055, 1064, 1.0]]}, "snippet": {"field": "default_text", "start": 751, "stop": 951, "weights": [[5, 8, 1.0], [25, 34, 1.0], [77, 80, 1.0], [81, 86, 1.0], [164, 167, 1.0], [168, 173, 1.0]]}}, {"doc_id": "2013.wwwconf_conference-2013c.138", "score": 19.52466677063915, "relevance": null, "rank": 4, "weights": {"doc_id": [], "default_text": [[65, 68, 1.0], [69, 74, 1.0], [94, 103, 1.0], [111, 114, 1.0], [217, 220, 1.0], [221, 226, 1.0], [253, 256, 1.0], [257, 262, 1.0], [422, 425, 1.0], [426, 431, 1.0], [581, 584, 1.0], [585, 590, 1.0], [729, 738, 1.0], [742, 745, 1.0], [1061, 1064, 1.0], [1065, 1070, 1.0], [1158, 1161, 1.0], [1162, 1167, 1.0], [1208, 1211, 1.0], [1212, 1217, 1.0], [1319, 1328, 1.0]]}, "snippet": {"field": "default_text", "start": 60, "stop": 260, "weights": [[5, 8, 1.0], [9, 14, 1.0], [34, 43, 1.0], [51, 54, 1.0], [157, 160, 1.0], [161, 166, 1.0], [193, 196, 1.0], [197, 202, 1.0]]}}, {"doc_id": "2005.cikm_conference-2005.139", "score": 18.961532460561408, "relevance": null, "rank": 5, "weights": {"doc_id": [], "default_text": [[11, 14, 1.0], [24, 33, 1.0], [81, 84, 1.0], [215, 218, 1.0], [279, 288, 1.0], [316, 319, 1.0], [320, 325, 1.0], [327, 330, 1.0], [456, 459, 1.0], [577, 582, 1.0], [784, 787, 1.0], [788, 793, 1.0]]}, "snippet": {"field": "default_text", "start": 210, "stop": 410, "weights": [[5, 8, 1.0], [69, 78, 1.0], [106, 109, 1.0], [110, 115, 1.0], [117, 120, 1.0]]}}, {"doc_id": "2003.wwwconf_workshop-2002webdyn.1", "score": 18.685631536198184, "relevance": null, "rank": 6, "weights": {"doc_id": [], "default_text": [[0, 3, 1.0], [18, 27, 1.0], [28, 31, 1.0], [147, 150, 1.0], [188, 193, 1.0], [296, 299, 1.0], [399, 404, 1.0], [555, 558, 1.0]]}, "snippet": {"field": "default_text", "start": 0, "stop": 200, "weights": [[0, 3, 1.0], [18, 27, 1.0], [28, 31, 1.0], [147, 150, 1.0], [188, 193, 1.0]]}}, {"doc_id": "2008.wwwconf_conference-2008.132", "score": 18.65211100050253, "relevance": null, "rank": 7, "weights": {"doc_id": [], "default_text": [[0, 3, 1.0], [127, 130, 1.0], [200, 209, 1.0], [213, 216, 1.0], [217, 222, 1.0]]}, "snippet": {"field": "default_text", "start": 122, "stop": 322, "weights": [[5, 8, 1.0], [78, 87, 1.0], [91, 94, 1.0], [95, 100, 1.0]]}}, {"doc_id": "2004.wwwconf_conference-2004.1", "score": 18.63814916175329, "relevance": null, "rank": 8, "weights": {"doc_id": [], "default_text": [[18, 21, 1.0], [28, 37, 1.0], [45, 48, 1.0], [132, 135, 1.0], [181, 184, 1.0], [319, 322, 1.0], [375, 384, 1.0], [504, 513, 1.0], [571, 576, 1.0], [609, 612, 1.0], [664, 669, 1.0], [767, 770, 1.0], [771, 776, 1.0], [901, 906, 1.0], [1253, 1258, 1.0], [1378, 1383, 1.0], [1570, 1573, 1.0]]}, "snippet": {"field": "default_text", "start": 13, "stop": 213, "weights": [[5, 8, 1.0], [15, 24, 1.0], [32, 35, 1.0], [119, 122, 1.0], [168, 171, 1.0]]}}, {"doc_id": "2008.wwwconf_conference-2008.205", "score": 18.54023386863689, "relevance": null, "rank": 9, "weights": {"doc_id": [], "default_text": [[34, 37, 1.0], [38, 43, 1.0], [97, 100, 1.0], [188, 191, 1.0], [211, 214, 1.0], [483, 492, 1.0], [496, 501, 1.0], [644, 649, 1.0]]}, "snippet": {"field": "default_text", "start": 29, "stop": 229, "weights": [[5, 8, 1.0], [9, 14, 1.0], [68, 71, 1.0], [159, 162, 1.0], [182, 185, 1.0]]}}, {"doc_id": "2007.wwwconf_conference-2007.203", "score": 18.24178651321283, "relevance": null, "rank": 10, "weights": {"doc_id": [], "default_text": [[33, 42, 1.0], [59, 62, 1.0], [93, 96, 1.0], [150, 153, 1.0], [487, 496, 1.0], [500, 503, 1.0], [581, 584, 1.0], [628, 637, 1.0], [659, 662, 1.0], [715, 718, 1.0]]}, "snippet": {"field": "default_text", "start": 482, "stop": 682, "weights": [[5, 14, 1.0], [18, 21, 1.0], [99, 102, 1.0], [146, 155, 1.0], [177, 180, 1.0]]}}], "run_2": [], "summary": [["10 unjudged doc(s) move to a top spot in the ranking"]], "mergedWeights": {}}], "docs": {"2019.sigirconf_workshop-2019ecom.19": {"doc_id": "2019.sigirconf_workshop-2019ecom.19", "default_text": "Ranking Sentences from Product Description & Bullets for Better Search Products in an ecommerce catalog contain information-rich fields like description and bullets that can be useful to extract entities (attributes) using NER based systems. However, these fields are often verbose and contain lot of information that is not relevant from a search perspective. Treating each sentence within these fields equally can lead to poor full text match and introduce problems in extracting attributes to develop ontologies, semantic search etc. To address this issue, we describe two methods based on extractive summarization with reinforcement learning by leveraging information in product titles and search click through logs to rank sentences from bullets, description, etc. Finally, we compare the precision of these two models.", "abstract": "Products in an ecommerce catalog contain information-rich fields like description and bullets that can be useful to extract entities (attributes) using NER based systems. However, these fields are often verbose and contain lot of information that is not relevant from a search perspective. Treating each sentence within these fields equally can lead to poor full text match and introduce problems in extracting attributes to develop ontologies, semantic search etc. To address this issue, we describe two methods based on extractive summarization with reinforcement learning by leveraging information in product titles and search click through logs to rank sentences from bullets, description, etc. Finally, we compare the precision of these two models.", "title": "Ranking Sentences from Product Description & Bullets for Better Search", "authors": ["Prateek Verma", "Aliasgar Kutiyanawala", "Ke Shen"], "year": "2019", "booktitle": "Proceedings of the SIGIR 2019 Workshop on eCommerce, co-located with the 42st International ACM SIGIR Conference on Research and Development in Information Retrieval, eCom@SIGIR 2019, Paris, France, July 25, 2019"}, "2018.sigirconf_workshop-2018ecom.5": {"doc_id": "2018.sigirconf_workshop-2018ecom.5", "default_text": "An Empirical Study of Using An Ensemble Model in e-Commerce Taxonomy Classification Challenge In the Rakuten data challenge on taxonomy Classification for eCommerce-scale Product Catalogs, we propose an approach based on deep convolutional neural networks to predict product taxonomies using their descriptions. The classification performance of the proposed system is further improved with oversampling, threshold moving and error correct output coding. The best classification accuracy is obtained through ensembling multiple networks trained differently with multiple inputs comprising of various extracted features.", "abstract": "In the Rakuten data challenge on taxonomy Classification for eCommerce-scale Product Catalogs, we propose an approach based on deep convolutional neural networks to predict product taxonomies using their descriptions. The classification performance of the proposed system is further improved with oversampling, threshold moving and error correct output coding. The best classification accuracy is obtained through ensembling multiple networks trained differently with multiple inputs comprising of various extracted features.", "title": "An Empirical Study of Using An Ensemble Model in e-Commerce Taxonomy Classification Challenge", "authors": ["Yugang Jia", "Xin Wang", "Hanqing Cao", "Boshu Ru", "Tianzhong Yang"], "year": "2018", "booktitle": "The SIGIR 2018 Workshop On eCommerce co-located with the 41st International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2018), Ann Arbor, Michigan, USA, July 12, 2018"}, "2018.sigirconf_workshop-2018ecom.14": {"doc_id": "2018.sigirconf_workshop-2018ecom.14", "default_text": "End-to-End Neural Ranking for eCommerce Product Search: an Application of Task Models and Textual Embeddings Yan. 2018. End-to-End Neural Ranking for eCommerce Product Search: An application of task models and textual embeddings. In Proceedings of ACM SIGIR Workshop on eCommerce (SIGIR 2018 eCom). ACM,", "abstract": "Yan. 2018. End-to-End Neural Ranking for eCommerce Product Search: An application of task models and textual embeddings. In Proceedings of ACM SIGIR Workshop on eCommerce (SIGIR 2018 eCom). ACM,", "title": "End-to-End Neural Ranking for eCommerce Product Search: an Application of Task Models and Textual Embeddings", "authors": ["Eliot Brenner", "Jun Zhao", "Aliasgar Kutiyanawala", "Zheng Yan"], "year": "2018", "booktitle": "The SIGIR 2018 Workshop On eCommerce co-located with the 41st International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2018), Ann Arbor, Michigan, USA, July 12, 2018"}, "2002.ntcir_workshop-2002.59": {"doc_id": "2002.ntcir_workshop-2002.59", "default_text": "Term Distillation for Cross-DB Retrieval In cross-DB retrieval, the domain of queries differs from the retrieval target in the distribution of that of term occurrences. This causes incorrect term weighting in the retrieval system which assigns to each term a retrieval weight based on the distribution of term occurrences. To resolve the problem, we propose \\term distillation\" which is a framework for query term selection in cross-DB retrieval. The experiments using the NTCIR patent retrieval test collection demonstrate that term distillation is e ective for cross-DB retrieval.", "abstract": "In cross-DB retrieval, the domain of queries differs from the retrieval target in the distribution of that of term occurrences. This causes incorrect term weighting in the retrieval system which assigns to each term a retrieval weight based on the distribution of term occurrences. To resolve the problem, we propose \\term distillation\" which is a framework for query term selection in cross-DB retrieval. The experiments using the NTCIR patent retrieval test collection demonstrate that term distillation is e ective for cross-DB retrieval.", "title": "Term Distillation for Cross-DB Retrieval", "authors": ["Hideo Itoh", "Hiroko Mano", "Yasushi Ogawa"], "year": "2002", "booktitle": "Proceedings of the Third NTCIR Workshop on Research in Information Retrieval, Automatic Text Summarization and Question Answering, NTCIR-3, Tokyo, Japan, October 8-10, 2002"}, "2010.clef_workshop-2010w.104": {"doc_id": "2010.clef_workshop-2010w.104", "default_text": "The University of Amsterdam's Concept Detection System at ImageCLEF 2010 Our group within the University of Amsterdam participated in the large-scale visual concept detection task of ImageCLEF 2010. The submissions from our visual concept detection system have resulted in the best visual-only run in the per-concept evaluation. In the per-image evaluation, it achieves the highest score in terms of example-based F-measure across all types of runs.", "abstract": "Our group within the University of Amsterdam participated in the large-scale visual concept detection task of ImageCLEF 2010. The submissions from our visual concept detection system have resulted in the best visual-only run in the per-concept evaluation. In the per-image evaluation, it achieves the highest score in terms of example-based F-measure across all types of runs.", "title": "The University of Amsterdam's Concept Detection System at ImageCLEF 2010", "authors": ["Koen E. A. van de Sande", "Theo Gevers"], "year": "2010", "booktitle": "CLEF 2010 LABs and Workshops, Notebook Papers, 22-23 September 2010, Padua, Italy"}, "2005.clef_workshop-2005w.97": {"doc_id": "2005.clef_workshop-2005w.97", "default_text": "The University of Amsterdam at WebCLEF 2005 We describe the University of Amsterdam's participation in the WebCLEF track at CLEF 2005. We submitted runs for both the mixed monolingual task and the multilingual task.", "abstract": "We describe the University of Amsterdam's participation in the WebCLEF track at CLEF 2005. We submitted runs for both the mixed monolingual task and the multilingual task.", "title": "The University of Amsterdam at WebCLEF 2005", "authors": ["Jaap Kamps", "Maarten de Rijke", "B\u00f6rkur Sigurbj\u00f6rnsson"], "year": "2005", "booktitle": "Working Notes for CLEF 2005 Workshop co-located with the 9th European Conference on Digital Libraries (ECDL 2005), Wien, Austria, September 21-22, 2005"}, "2009.clef_workshop-20092.32": {"doc_id": "2009.clef_workshop-20092.32", "default_text": "The University of Amsterdam's Concept Detection System at ImageCLEF 2009 ", "abstract": "", "title": "The University of Amsterdam's Concept Detection System at ImageCLEF 2009", "authors": ["Koen E. A. van de Sande", "Theo Gevers", "Arnold W. M. Smeulders"], "year": "2009", "booktitle": "Multilingual Information Access Evaluation II. Multimedia Experiments - 10th Workshop of the Cross-Language Evaluation Forum, CLEF 2009, Corfu, Greece, September 30 - October 2, 2009, Revised Selected Papers"}, "2006.clef_workshop-2006w.110": {"doc_id": "2006.clef_workshop-2006w.110", "default_text": "The University of Amsterdam at CLEF@QA 2006 ", "abstract": "", "title": "The University of Amsterdam at CLEF@QA 2006", "authors": ["Valentin Jijkoun", "Joris van Rantwijk", "David Ahn", "Erik F. Tjong Kim Sang", "Maarten de Rijke"], "year": "2006", "booktitle": "Working Notes for CLEF 2006 Workshop co-located with the 10th European Conference on Digital Libraries (ECDL 2006), Alicante, Spain, September 20-22, 2006"}, "2007.clef_workshop-2007.43": {"doc_id": "2007.clef_workshop-2007.43", "default_text": "The University of Amsterdam's Question Answering System at QA@CLEF 2007 ", "abstract": "", "title": "The University of Amsterdam's Question Answering System at QA@CLEF 2007", "authors": ["Valentin Jijkoun", "Katja Hofmann", "David Ahn", "Mahboob Alam Khalid", "Joris van Rantwijk", "Maarten de Rijke", "Erik F. Tjong Kim Sang"], "year": "2007", "booktitle": "Advances in Multilingual and Multimodal Information Retrieval, 8th Workshop of the Cross-Language Evaluation Forum, CLEF 2007, Budapest, Hungary, September 19-21, 2007, Revised Selected Papers"}, "2007.clef_workshop-2007w.112": {"doc_id": "2007.clef_workshop-2007w.112", "default_text": "The University of Amsterdam at the CLEF Cross Language Speech Retrieval Track 2007 In this paper we present the contents of the University of Amsterdam submission in the CLEF Cross Language Speech Retrieval 2007 English task. We describe the effects of using character n-grams and field combinations on both monolingual English retrieval, and crosslingual Dutch to English retrieval.", "abstract": "In this paper we present the contents of the University of Amsterdam submission in the CLEF Cross Language Speech Retrieval 2007 English task. We describe the effects of using character n-grams and field combinations on both monolingual English retrieval, and crosslingual Dutch to English retrieval.", "title": "The University of Amsterdam at the CLEF Cross Language Speech Retrieval Track 2007", "authors": ["Bouke Huurnink"], "year": "2007", "booktitle": "Working Notes for CLEF 2007 Workshop co-located with the 11th European Conference on Digital Libraries (ECDL 2007), Budapest, Hungary, September 19-21, 2007"}, "2011.wwwconf_workshop-2011ldow.14": {"doc_id": "2011.wwwconf_workshop-2011ldow.14", "default_text": "Open eBusiness Ontology Usage: Investigating Community Implementation of GoodRelations The GoodRelations Ontology is experiencing the first stages of mainstream adoption, with its appeal to a range of enterprises as the eCommerce ontology of choice to promote its product catalogue. As adoption increases, so too does the need to review and analyze current implementation of the ontology to better inform future usage and uptake. To comprehensively understand the implementation approaches, usage patterns, instance data and model coverage, data was collected from 105 different web based sources that have published their business and product-related information using the GoodRelations Ontology. This paper analyses the ontology usage in terms of data instantiation, and conceptual coverage using SPARQL queries to evaluate quality, usefulness and inference provisioning. Experimental results highlight that early publishers of structured eCommerce data benefit more due to structured data being more readily search engine indexable, but the lack of available product ontologies and product master datasheets is impeding the creation of a semantically interlinked eCommerce Web.", "abstract": "The GoodRelations Ontology is experiencing the first stages of mainstream adoption, with its appeal to a range of enterprises as the eCommerce ontology of choice to promote its product catalogue. As adoption increases, so too does the need to review and analyze current implementation of the ontology to better inform future usage and uptake. To comprehensively understand the implementation approaches, usage patterns, instance data and model coverage, data was collected from 105 different web based sources that have published their business and product-related information using the GoodRelations Ontology. This paper analyses the ontology usage in terms of data instantiation, and conceptual coverage using SPARQL queries to evaluate quality, usefulness and inference provisioning. Experimental results highlight that early publishers of structured eCommerce data benefit more due to structured data being more readily search engine indexable, but the lack of available product ontologies and product master datasheets is impeding the creation of a semantically interlinked eCommerce Web.", "title": "Open eBusiness Ontology Usage: Investigating Community Implementation of GoodRelations", "authors": ["Jamshaid Ashraf", "Richard Cyganiak", "Se\u00e1n O'Riain", "Maja Hadzic"], "year": "2011", "booktitle": "WWW2011 Workshop on Linked Data on the Web, Hyderabad, India, March 29, 2011"}, "2003.wwwconf_workshop-2002webdyn.1": {"doc_id": "2003.wwwconf_workshop-2002webdyn.1", "default_text": "Web Structure and Evolution Web Structure, Age, and Page Quality This paper is aimed at the study of quantitative measures of the relation between Web structure, age, and quality o f W eb pages. Quality is studied from di erent link-based metrics and their relationship with the structure of the Web and the last modi cation time of a page. We show that, as expected, Pagerank is biased against new pages. As a subproduct we propose a P agerank variant that includes age into account a n d w e obtain information on how the rate of change is related with Web structure.", "abstract": "This paper is aimed at the study of quantitative measures of the relation between Web structure, age, and quality o f W eb pages. Quality is studied from di erent link-based metrics and their relationship with the structure of the Web and the last modi cation time of a page. We show that, as expected, Pagerank is biased against new pages. As a subproduct we propose a P agerank variant that includes age into account a n d w e obtain information on how the rate of change is related with Web structure.", "title": "Web Structure and Evolution Web Structure, Age, and Page Quality", "authors": ["Ricardo A. Baeza-Yates", "Felipe Saint-Jean", "Carlos Castillo"], "year": "2002", "booktitle": "Proceedings of the Second International Workshop on Web Dynamics, WebDyn@WWW 2002, Honululu, HW, USA, May 7, 2002"}, "2005.wwwconf_workshop-2004webdyn.11": {"doc_id": "2005.wwwconf_workshop-2004webdyn.11", "default_text": "WebRelievo: A System for Browsing and Analyzing the Evolution of Related Web Pages WebRelievo is a system for browsing and analyzing the evolution of the web graph structure based on link analysis. This system enables us to answer historical questions, and to detect changes in topics on the Web. WebRelievo extracts web pages related to a focused page using link analysis, and visualizes the evolution of their relationships with a time series of graphs. This visualization enables us to understand when related pages appeared, and how their relationships have evolved over time. The user can interactively browse those related pages by changing the focused page and by changing layouts of graphs. WebRelievo is implemented on six Japanese web archives crawled from 1999 to 2003.", "abstract": "WebRelievo is a system for browsing and analyzing the evolution of the web graph structure based on link analysis. This system enables us to answer historical questions, and to detect changes in topics on the Web. WebRelievo extracts web pages related to a focused page using link analysis, and visualizes the evolution of their relationships with a time series of graphs. This visualization enables us to understand when related pages appeared, and how their relationships have evolved over time. The user can interactively browse those related pages by changing the focused page and by changing layouts of graphs. WebRelievo is implemented on six Japanese web archives crawled from 1999 to 2003.", "title": "WebRelievo: A System for Browsing and Analyzing the Evolution of Related Web Pages", "authors": ["Masashi Toyoda", "Masaru Kitsuregawa"], "year": "2004", "booktitle": "Proceedings of the Third International Workshop on Web Dynamics, WebDyn@WWW 2004, New York, NY, USA, May 18, 2004"}, "2011.sigirconf_conference-2011.10": {"doc_id": "2011.sigirconf_conference-2011.10", "default_text": "User behavior in zero-recall ecommerce queries ABSTRACTUser expectation and experience for web search and eCommerce (product) search are quite different. Product descriptions are concise as compared to typical web documents. User expectation is more specific to find the right product. The difference in the publisher and searcher vocabulary (in case of product search the seller and the buyer vocabulary) combined with the fact that there are fewer products to search over than web documents result in observable numbers of searches that return no results (zero recall searches). In this paper we describe a study of zero recall searches. Our study is focused on eCommerce search and uses data from a leading eCommerce site's user click stream logs. There are 3 main contributions of our study: 1) The cause of zero recall searches; 2) A study of user's reaction and recovery from zero recall; 3) A study of differences in behavior of power users versus novice users to zero recall searches.", "abstract": "ABSTRACTUser expectation and experience for web search and eCommerce (product) search are quite different. Product descriptions are concise as compared to typical web documents. User expectation is more specific to find the right product. The difference in the publisher and searcher vocabulary (in case of product search the seller and the buyer vocabulary) combined with the fact that there are fewer products to search over than web documents result in observable numbers of searches that return no results (zero recall searches). In this paper we describe a study of zero recall searches. Our study is focused on eCommerce search and uses data from a leading eCommerce site's user click stream logs. There are 3 main contributions of our study: 1) The cause of zero recall searches; 2) A study of user's reaction and recovery from zero recall; 3) A study of differences in behavior of power users versus novice users to zero recall searches.", "title": "User behavior in zero-recall ecommerce queries", "authors": ["Gyanit Singh", "Nish Parikh", "Neel Sundaresan"], "year": "2011", "booktitle": "Proceeding of the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2011, Beijing, China, July 25-29, 2011"}, "2008.sigirconf_conference-2008.170": {"doc_id": "2008.sigirconf_conference-2008.170", "default_text": "Locating relevant text within XML documents ABSTRACTTraditional document retrieval has shown to be a competitive approach in XML element retrieval, which is counter-intuitive since the element retrieval task requests all and only relevant document parts to be retrieved. This paper conducts a comparative analysis of document and element retrieval, highlights the relative strengths and weaknesses of both approaches, and explains the relative effectiveness of document retrieval approaches at element retrieval tasks.", "abstract": "ABSTRACTTraditional document retrieval has shown to be a competitive approach in XML element retrieval, which is counter-intuitive since the element retrieval task requests all and only relevant document parts to be retrieved. This paper conducts a comparative analysis of document and element retrieval, highlights the relative strengths and weaknesses of both approaches, and explains the relative effectiveness of document retrieval approaches at element retrieval tasks.", "title": "Locating relevant text within XML documents", "authors": ["Jaap Kamps", "Marijn Koolen", "Mounia Lalmas"], "year": "2008", "booktitle": "Proceedings of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2008, Singapore, July 20-24, 2008"}, "2018.sigirconf_conference-2018.230": {"doc_id": "2018.sigirconf_conference-2018.230", "default_text": "SIGIR 2018 Workshop on eCommerce (ECOM18) ABSTRACTeCommerce Information Retrieval has received little attention in the academic literature, yet it is an essential component of some of the largest web sites (such as eBay, Amazon, Airbnb, Alibaba, Taobao, Target, Facebook, and others). SIGIR has for several years seen sponsorship from these kinds of organisations, who clearly value the importance of research into Information Retrieval. The purpose of this workshop is to bring together researchers and practitioners of eCommerce IR to discuss topics unique to it, to set a research agenda, and to examine how to build datasets for research into this fascinating topic.eCommerce IR is ripe for research and has a unique set of problems. For example, in eCommerce search there may be no hypertext links between documents (products); there is a click stream, but more importantly, there is often a buy stream. eCommerce problems are wide in scope and range from user interaction modalities (the kinds of search seen in when buying are different from those of web-page search (i.e. it is not clear how shopping and buying relate to the standard web-search interaction models)) through to dynamic updates of a rapidly changing collection on auction sites, and the experienceness of some products (such as Airbnb bookings).This workshop is a follow up to the \"SIGIR 2017 workshop on eCommerce (ECOM17)\", which was organized at SIGIR 2017, Tokyo. In the 2018 workshop, in addition to a data challenge, we will be following up on multiple aspects that were discussed in the 2017 workshop.", "abstract": "ABSTRACTeCommerce Information Retrieval has received little attention in the academic literature, yet it is an essential component of some of the largest web sites (such as eBay, Amazon, Airbnb, Alibaba, Taobao, Target, Facebook, and others). SIGIR has for several years seen sponsorship from these kinds of organisations, who clearly value the importance of research into Information Retrieval. The purpose of this workshop is to bring together researchers and practitioners of eCommerce IR to discuss topics unique to it, to set a research agenda, and to examine how to build datasets for research into this fascinating topic.eCommerce IR is ripe for research and has a unique set of problems. For example, in eCommerce search there may be no hypertext links between documents (products); there is a click stream, but more importantly, there is often a buy stream. eCommerce problems are wide in scope and range from user interaction modalities (the kinds of search seen in when buying are different from those of web-page search (i.e. it is not clear how shopping and buying relate to the standard web-search interaction models)) through to dynamic updates of a rapidly changing collection on auction sites, and the experienceness of some products (such as Airbnb bookings).This workshop is a follow up to the \"SIGIR 2017 workshop on eCommerce (ECOM17)\", which was organized at SIGIR 2017, Tokyo. In the 2018 workshop, in addition to a data challenge, we will be following up on multiple aspects that were discussed in the 2017 workshop.", "title": "SIGIR 2018 Workshop on eCommerce (ECOM18)", "authors": ["Jon Degenhardt", "Pino Di Fabbrizio", "Surya Kallumadi", "Mohit Kumar", "Yiu-Chang Lin", "Andrew Trotman", "Huasha Zhao"], "year": "2018", "booktitle": "The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval, SIGIR 2018, Ann Arbor, MI, USA, July 08-12, 2018"}, "2013.sigirconf_conference-2013.125": {"doc_id": "2013.sigirconf_conference-2013.125", "default_text": "Relating retrievability, performance and length ABSTRACTRetrievability provides a different way to evaluate an Information Retrieval (IR) system as it focuses on how easily documents can be found. It is intrinsically related to retrieval performance because a document needs to be retrieved before it can be judged relevant. In this paper, we undertake an empirical investigation into the relationship between the retrievability of documents, the retrieval bias imposed by a retrieval system, and the retrieval performance, across different amounts of document length normalization. To this end, two standard IR models are used on three TREC test collections to show that there is a useful and practical link between retrievability and performance. Our findings show that minimizing the bias across the document collection leads to good performance (though not the best performance possible). We also show that past a certain amount of document length normalization the retrieval bias increases, and the retrieval performance significantly and rapidly decreases. These findings suggest that the relationship between retrievability and effectiveness may offer a way to automatically tune systems.", "abstract": "ABSTRACTRetrievability provides a different way to evaluate an Information Retrieval (IR) system as it focuses on how easily documents can be found. It is intrinsically related to retrieval performance because a document needs to be retrieved before it can be judged relevant. In this paper, we undertake an empirical investigation into the relationship between the retrievability of documents, the retrieval bias imposed by a retrieval system, and the retrieval performance, across different amounts of document length normalization. To this end, two standard IR models are used on three TREC test collections to show that there is a useful and practical link between retrievability and performance. Our findings show that minimizing the bias across the document collection leads to good performance (though not the best performance possible). We also show that past a certain amount of document length normalization the retrieval bias increases, and the retrieval performance significantly and rapidly decreases. These findings suggest that the relationship between retrievability and effectiveness may offer a way to automatically tune systems.", "title": "Relating retrievability, performance and length", "authors": ["Colin Wilkie", "Leif Azzopardi"], "year": "2013", "booktitle": "The 36th International ACM SIGIR conference on research and development in Information Retrieval, SIGIR '13, Dublin, Ireland - July 28 - August 01, 2013"}, "2005.sigirconf_conference-2005.64": {"doc_id": "2005.sigirconf_conference-2005.64", "default_text": "An exploration of axiomatic approaches to information retrieval ABSTRACTExisting retrieval models generally do not offer any guarantee for optimal retrieval performance. Indeed, it is even difficult, if not impossible, to predict a model's empirical performance analytically. This limitation is at least partly caused by the way existing retrieval models are developed where relevance is only coarsely modeled at the level of documents and queries as opposed to a finer granularity level of terms. In this paper, we present a new axiomatic approach to developing retrieval models based on direct modeling of relevance with formalized retrieval constraints defined at the level of terms. The basic idea of this axiomatic approach is to search in a space of candidate retrieval functions for one that can satisfy a set of reasonable retrieval constraints. To constrain the search space, we propose to define a retrieval function inductively and decompose a retrieval function into three component functions. Inspired by the analysis of the existing retrieval functions with the inductive definition, we derive several new retrieval functions using the axiomatic retrieval framework. Experiment results show that the derived new retrieval functions are more robust and less sensitive to parameter settings than the existing retrieval functions with comparable optimal performance.", "abstract": "ABSTRACTExisting retrieval models generally do not offer any guarantee for optimal retrieval performance. Indeed, it is even difficult, if not impossible, to predict a model's empirical performance analytically. This limitation is at least partly caused by the way existing retrieval models are developed where relevance is only coarsely modeled at the level of documents and queries as opposed to a finer granularity level of terms. In this paper, we present a new axiomatic approach to developing retrieval models based on direct modeling of relevance with formalized retrieval constraints defined at the level of terms. The basic idea of this axiomatic approach is to search in a space of candidate retrieval functions for one that can satisfy a set of reasonable retrieval constraints. To constrain the search space, we propose to define a retrieval function inductively and decompose a retrieval function into three component functions. Inspired by the analysis of the existing retrieval functions with the inductive definition, we derive several new retrieval functions using the axiomatic retrieval framework. Experiment results show that the derived new retrieval functions are more robust and less sensitive to parameter settings than the existing retrieval functions with comparable optimal performance.", "title": "An exploration of axiomatic approaches to information retrieval", "authors": ["Hui Fang", "ChengXiang Zhai"], "year": "2005", "booktitle": "SIGIR 2005: Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, Salvador, Brazil, August 15-19, 2005"}, "2017.sigirconf_conference-2017.251": {"doc_id": "2017.sigirconf_conference-2017.251", "default_text": "SIGIR 2017 Workshop on eCommerce (ECOM17) ABSTRACTeCommerce Information Retrieval has received little attention in the academic literature, yet it is an essential component of some of the largest web sites (such as eBay, Amazon, Airbnb, Alibaba, Taobao, Target, Facebook, and others). SIGIR has for several years seen sponsorship from these kinds of organisations, who clearly value the importance of research into Information Retrieval. This workshop brings together researchers and practitioners of eCommerce IR to discuss topics unique to it, to set a research agenda, and to examine how to build a dataset for research into this fascinating topic.eCommerce IR is ripe for research and has a unique set of problems. For example, in eCommerce search there may be no hypertext links between documents (products); there is a click stream, but more importantly, there is often a buy stream. eCommerce problems are wide in scope and range from user interaction modalities (the kinds of search seen in when buying are different from those of web-page search (i.e. it is not clear how shopping and buying relate to the standard web-search interaction models)) through to dynamic updates of a rapidly changing collection on auction sites, and the experienceness of some products (such as Airbnb bookings).", "abstract": "ABSTRACTeCommerce Information Retrieval has received little attention in the academic literature, yet it is an essential component of some of the largest web sites (such as eBay, Amazon, Airbnb, Alibaba, Taobao, Target, Facebook, and others). SIGIR has for several years seen sponsorship from these kinds of organisations, who clearly value the importance of research into Information Retrieval. This workshop brings together researchers and practitioners of eCommerce IR to discuss topics unique to it, to set a research agenda, and to examine how to build a dataset for research into this fascinating topic.eCommerce IR is ripe for research and has a unique set of problems. For example, in eCommerce search there may be no hypertext links between documents (products); there is a click stream, but more importantly, there is often a buy stream. eCommerce problems are wide in scope and range from user interaction modalities (the kinds of search seen in when buying are different from those of web-page search (i.e. it is not clear how shopping and buying relate to the standard web-search interaction models)) through to dynamic updates of a rapidly changing collection on auction sites, and the experienceness of some products (such as Airbnb bookings).", "title": "SIGIR 2017 Workshop on eCommerce (ECOM17)", "authors": ["Jon Degenhardt", "Surya Kallumadi", "Maarten de Rijke", "Luo Si", "Andrew Trotman", "Yinghui Xu"], "year": "2017", "booktitle": "Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval, Shinjuku, Tokyo, Japan, August 7-11, 2017"}, "1981.sigirconf_conference-81.7": {"doc_id": "1981.sigirconf_conference-81.7", "default_text": "An Approach to Probabilistic Retrieval ABSTRACTThe objective is to relate the effectiveness of retrieval, the fuzzy set concept and the processing of Boolean query. The use of a probabilistic retrieval scheme is motivated. It is found that there is a correspondence between probabilistic retrieval schmes and fuzzy sets. A fuzzy set corresponding to a potentially optimal probabilistic retrieval scheme is obtained. Then the retrieval scheme for the fuzzy set is constructed.", "abstract": "ABSTRACTThe objective is to relate the effectiveness of retrieval, the fuzzy set concept and the processing of Boolean query. The use of a probabilistic retrieval scheme is motivated. It is found that there is a correspondence between probabilistic retrieval schmes and fuzzy sets. A fuzzy set corresponding to a potentially optimal probabilistic retrieval scheme is obtained. Then the retrieval scheme for the fuzzy set is constructed.", "title": "An Approach to Probabilistic Retrieval", "authors": ["Clement T. Yu", "K. Lam"], "year": "1981", "booktitle": "Theoretical Issues in Information Retrieval, Proceedings of the Fourth International Conference on Information Storage and Retrieval, Oakland, California, USA, May 31 - June 2, 1981"}, "2003.sigirconf_conference-2003.73": {"doc_id": "2003.sigirconf_conference-2003.73", "default_text": "XML retrieval: what to retrieve? ABSTRACTThe fundamental difference between standard information retrieval and XML retrieval is the unit of retrieval. In traditional IR, the unit of retrieval is fixed: it is the complete document. In XML retrieval, every XML element in a document is a retrievable unit. This makes XML retrieval more difficult: besides being relevant, a retrieved unit should be neither too large nor too small. The research presented here, a comparative analysis of two approaches to XML retrieval, aims to shed light on which XML elements should be retrieved. The experimental evaluation uses data from the Initiative for the Evaluation of XML retrieval (INEX 2002).", "abstract": "ABSTRACTThe fundamental difference between standard information retrieval and XML retrieval is the unit of retrieval. In traditional IR, the unit of retrieval is fixed: it is the complete document. In XML retrieval, every XML element in a document is a retrievable unit. This makes XML retrieval more difficult: besides being relevant, a retrieved unit should be neither too large nor too small. The research presented here, a comparative analysis of two approaches to XML retrieval, aims to shed light on which XML elements should be retrieved. The experimental evaluation uses data from the Initiative for the Evaluation of XML retrieval (INEX 2002).", "title": "XML retrieval: what to retrieve?", "authors": ["Jaap Kamps", "Maarten Marx", "Maarten de Rijke", "B\u00f6rkur Sigurbj\u00f6rnsson"], "year": "2003", "booktitle": "SIGIR 2003: Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, July 28 - August 1, 2003, Toronto, Canada"}, "2016.wsdm_conference-2016.14": {"doc_id": "2016.wsdm_conference-2016.14", "default_text": "Publication Date Prediction through Reverse Engineering of the Web ABSTRACTIn this paper, we focus on one of the most challenging tasks in temporal information retrieval: detection of a web page publication date. The natural approach to this problem is to find the publication date in the HTML body of a page. However, there are two fundamental problems with this approach. First, not all web pages contain the publication dates in their texts. Second, it is hard to distinguish the publication date among all the dates found in the page's text.The approach we suggest in this paper supplements methods of date extraction from the page's text with novel linkbased methods of dating. Some of our link-based methods are based on a probabilistic model of the Web graph structure evolution, which relies on the publication dates of web pages as on its parameters. We use this model to estimate the publication dates of web pages: based only on the link structure currently observed, we perform a \"reverse engineering\" to reveal the whole process of the Web's evolution.", "abstract": "ABSTRACTIn this paper, we focus on one of the most challenging tasks in temporal information retrieval: detection of a web page publication date. The natural approach to this problem is to find the publication date in the HTML body of a page. However, there are two fundamental problems with this approach. First, not all web pages contain the publication dates in their texts. Second, it is hard to distinguish the publication date among all the dates found in the page's text.The approach we suggest in this paper supplements methods of date extraction from the page's text with novel linkbased methods of dating. Some of our link-based methods are based on a probabilistic model of the Web graph structure evolution, which relies on the publication dates of web pages as on its parameters. We use this model to estimate the publication dates of web pages: based only on the link structure currently observed, we perform a \"reverse engineering\" to reveal the whole process of the Web's evolution.", "title": "Publication Date Prediction through Reverse Engineering of the Web", "authors": ["Liudmila Ostroumova Prokhorenkova", "Petr Prokhorenkov", "Egor Samosvat", "Pavel Serdyukov"], "year": "2016", "booktitle": "Proceedings of the Ninth ACM International Conference on Web Search and Data Mining, San Francisco, CA, USA, February 22-25, 2016"}, "2020.wsdm_conference-2020.4": {"doc_id": "2020.wsdm_conference-2020.4", "default_text": "Can Deep Learning Only Be Neural Networks? The word \"deep learning\" is generally regarded as a synonym of \"deep neural networks (DNNs)\". In this talk, we will discuss on essentials in deep learning and claim that deep learning is not necessarily to be realized by neural networks and differentiable modules. We will then present an exploration to non-NN style deep learning, where the building blocks are non-differentiable modules and the training process does not rely on backpropagation or gradient-based adjustment. We will also talk about some recent advances and challenges in this direction of research.", "abstract": "The word \"deep learning\" is generally regarded as a synonym of \"deep neural networks (DNNs)\". In this talk, we will discuss on essentials in deep learning and claim that deep learning is not necessarily to be realized by neural networks and differentiable modules. We will then present an exploration to non-NN style deep learning, where the building blocks are non-differentiable modules and the training process does not rely on backpropagation or gradient-based adjustment. We will also talk about some recent advances and challenges in this direction of research.", "title": "Can Deep Learning Only Be Neural Networks?", "authors": ["Zhi-Hua Zhou"], "year": "2020", "booktitle": "WSDM '20: The Thirteenth ACM International Conference on Web Search and Data Mining, Houston, TX, USA, February 3-7, 2020"}, "2020.wsdm_conference-2020.126": {"doc_id": "2020.wsdm_conference-2020.126", "default_text": "Decision Boundary of Deep Neural Networks: Challenges and Opportunities One crucial aspect that yet remains fairly unknown while can inform us about the behavior of deep neural networks is their decision boundaries. Trust can be improved once we understand how and why deep models carve out a particular form of decision boundary and thus make particular decisions. Robustness against adversarial examples is directly related to the decision boundary as adversarial examples are basically 'missed out' by the decision boundary between two classes. Investigating the decision boundary of deep neural networks, nevertheless, faces tremendous challenges. First, how we can generate instances near the decision boundary that are similar to real samples? Second, how we can leverage near decision boundary instances to characterize the behaviour of deep neural networks? Motivated to solve these challenges, we focus on investigating the decision boundary of deep neural network classifiers. In particular, we propose a novel approach to generate instances near decision boundary of pre-trained DNNs and then leverage these instances to characterize the behaviour of deep models. CCS CONCEPTS \u2022 Computing methodologies \u2192 Neural networks; Causal reasoning and diagnostics; Computer vision; Supervised learning.", "abstract": "One crucial aspect that yet remains fairly unknown while can inform us about the behavior of deep neural networks is their decision boundaries. Trust can be improved once we understand how and why deep models carve out a particular form of decision boundary and thus make particular decisions. Robustness against adversarial examples is directly related to the decision boundary as adversarial examples are basically 'missed out' by the decision boundary between two classes. Investigating the decision boundary of deep neural networks, nevertheless, faces tremendous challenges. First, how we can generate instances near the decision boundary that are similar to real samples? Second, how we can leverage near decision boundary instances to characterize the behaviour of deep neural networks? Motivated to solve these challenges, we focus on investigating the decision boundary of deep neural network classifiers. In particular, we propose a novel approach to generate instances near decision boundary of pre-trained DNNs and then leverage these instances to characterize the behaviour of deep models. CCS CONCEPTS \u2022 Computing methodologies \u2192 Neural networks; Causal reasoning and diagnostics; Computer vision; Supervised learning.", "title": "Decision Boundary of Deep Neural Networks: Challenges and Opportunities", "authors": ["Hamid Karimi", "Jiliang Tang"], "year": "2020", "booktitle": "WSDM '20: The Thirteenth ACM International Conference on Web Search and Data Mining, Houston, TX, USA, February 3-7, 2020"}, "2015.mir_conference-2015.49": {"doc_id": "2015.mir_conference-2015.49", "default_text": "A Deep Neural Network for Modeling Music ", "abstract": "", "title": "A Deep Neural Network for Modeling Music", "authors": ["Pengjing Zhang", "Xiaoqing Zheng", "Wenqiang Zhang", "Siyan Li", "Sheng Qian", "Wenqi He", "Shangtong Zhang", "Ziyuan Wang"], "year": "2015", "booktitle": "Proceedings of the 5th ACM on International Conference on Multimedia Retrieval, Shanghai, China, June 23-26, 2015"}, "2017.mir_conference-2017.38": {"doc_id": "2017.mir_conference-2017.38", "default_text": "Embedding Watermarks into Deep Neural Networks ", "abstract": "", "title": "Embedding Watermarks into Deep Neural Networks", "authors": ["Yusuke Uchida", "Yuki Nagai", "Shigeyuki Sakazawa", "Shin'ichi Satoh"], "year": "2017", "booktitle": "Proceedings of the 2017 ACM on International Conference on Multimedia Retrieval, ICMR 2017, Bucharest, Romania, June 6-9, 2017"}, "2019.cikm_conference-2019.187": {"doc_id": "2019.cikm_conference-2019.187", "default_text": "Scalable Causal Graph Learning through a Deep Neural Network ", "abstract": "", "title": "Scalable Causal Graph Learning through a Deep Neural Network", "authors": ["Chenxiao Xu", "Hao Huang", "Shinjae Yoo"], "year": "2019", "booktitle": "Proceedings of the 28th ACM International Conference on Information and Knowledge Management, CIKM 2019, Beijing, China, November 3-7, 2019"}, "2005.cikm_conference-2005.139": {"doc_id": "2005.cikm_conference-2005.139", "default_text": "Effects of web document evolution on genre classification ABSTRACTThe World Wide Web is a massive corpus that constantly evolves. Classification experiments usually grab a snapshot (temporally and spatially) of the Web for a corpus. In this paper, we examine the effects of page evolution on genre classification of Web pages. Web genre refers to the type of the page characterized by features such as style, form or presentation layout, and meta-content; Web genre can be used to tune spider crawling re-visits and inform relevance judgments for search engines. We found that pages in some genres change rarely if at all and can be used in present-day research experiments without requiring an updated version. We show that an old corpus can be used for training when testing on new Web pages, with only a marginal drop in accuracy rates on genre classification. We also show that features found to be useful in one corpus do not transfer well to other corpora with different genres.", "abstract": "ABSTRACTThe World Wide Web is a massive corpus that constantly evolves. Classification experiments usually grab a snapshot (temporally and spatially) of the Web for a corpus. In this paper, we examine the effects of page evolution on genre classification of Web pages. Web genre refers to the type of the page characterized by features such as style, form or presentation layout, and meta-content; Web genre can be used to tune spider crawling re-visits and inform relevance judgments for search engines. We found that pages in some genres change rarely if at all and can be used in present-day research experiments without requiring an updated version. We show that an old corpus can be used for training when testing on new Web pages, with only a marginal drop in accuracy rates on genre classification. We also show that features found to be useful in one corpus do not transfer well to other corpora with different genres.", "title": "Effects of web document evolution on genre classification", "authors": ["Elizabeth Sugar Boese", "Adele E. Howe"], "year": "2005", "booktitle": "Proceedings of the 2005 ACM CIKM International Conference on Information and Knowledge Management, Bremen, Germany, October 31 - November 5, 2005"}, "2017.cikm_conference-2017.312": {"doc_id": "2017.cikm_conference-2017.312", "default_text": "Spectrum-based Deep Neural Networks for Fraud Detection ABSTRACTIn this paper, we focus on fraud detection on a signed graph with only a small set of labeled training data. We propose a novel framework that combines deep neural networks and spectral graph analysis. In particular, we use the node projection (called as spectral coordinate) in the low dimensional spectral space of the graph's adjacency matrix as the input of deep neural networks. Spectral coordinates in the spectral space capture the most useful topology information of the network. Due to the small dimension of spectral coordinates (compared with the dimension of the adjacency matrix derived from a graph), training deep neural networks becomes feasible. We develop and evaluate two neural networks, deep autoencoder and convolutional neural network, in our fraud detection framework. Experimental results on a real signed graph show that our spectrum based deep neural networks are e ective in fraud detection.", "abstract": "ABSTRACTIn this paper, we focus on fraud detection on a signed graph with only a small set of labeled training data. We propose a novel framework that combines deep neural networks and spectral graph analysis. In particular, we use the node projection (called as spectral coordinate) in the low dimensional spectral space of the graph's adjacency matrix as the input of deep neural networks. Spectral coordinates in the spectral space capture the most useful topology information of the network. Due to the small dimension of spectral coordinates (compared with the dimension of the adjacency matrix derived from a graph), training deep neural networks becomes feasible. We develop and evaluate two neural networks, deep autoencoder and convolutional neural network, in our fraud detection framework. Experimental results on a real signed graph show that our spectrum based deep neural networks are e ective in fraud detection.", "title": "Spectrum-based Deep Neural Networks for Fraud Detection", "authors": ["Shuhan Yuan", "Xintao Wu", "Jun Li", "Aidong Lu"], "year": "2017", "booktitle": "Proceedings of the 2017 ACM on Conference on Information and Knowledge Management, CIKM 2017, Singapore, November 06 - 10, 2017"}, "2019.spire_conference-2019.4": {"doc_id": "2019.spire_conference-2019.4", "default_text": "Position Bias Estimation for Unbiased Learning-to-Rank in eCommerce Search ", "abstract": "", "title": "Position Bias Estimation for Unbiased Learning-to-Rank in eCommerce Search", "authors": ["Grigor Aslanyan", "Utkarsh Porwal"], "year": "2019", "booktitle": "String Processing and Information Retrieval - 26th International Symposium, SPIRE 2019, Segovia, Spain, October 7-9, 2019, Proceedings"}, "2015.ictir_conference-2015.2": {"doc_id": "2015.ictir_conference-2015.2", "default_text": "Theory of Retrieval: The Retrievability of Information ABSTRACTRetrievability is an important and interesting indicator that can be used in a number of ways to analyse Information Retrieval systems and document collections. Rather than focusing totally on relevance, retrievability examines what is retrieved, how often it is retrieved, and whether a user is likely to retrieve it or not. This is important because a document needs to be retrieved, before it can be judged for relevance. In this tutorial, we shall explain the concept of retrievability along with a number of retrievability measures, how it can be estimated and how it can be used for analysis. Since retrieval precedes relevance, we shall also provide an overview of how retrievability relates to effectivenessdescribing some of the insights that researchers have discovered thus far. We shall also show how retrievability relates to efficiency, and how the theory of retrievability can be used to improve both effectiveness and efficiency. Then we shall provide an overview of the different applications of retrievability such as Search Engine Bias, Corpus Profiling, etc., before wrapping up with challenges and opportunities. The final session will look at example problems and ways to analyse and apply retrievability to other problems and domains. Participants are invited to bring their own problems to be discussed after the tutorial. This half-day tutorial is ideal for: (i) researchers curious about retrievability and wanting to see how it can impact their research, (ii) researchers who would like to expand their set of analysis techniques, and/or (iii) researchers who would like to use retrievability to perform their own analysis.", "abstract": "ABSTRACTRetrievability is an important and interesting indicator that can be used in a number of ways to analyse Information Retrieval systems and document collections. Rather than focusing totally on relevance, retrievability examines what is retrieved, how often it is retrieved, and whether a user is likely to retrieve it or not. This is important because a document needs to be retrieved, before it can be judged for relevance. In this tutorial, we shall explain the concept of retrievability along with a number of retrievability measures, how it can be estimated and how it can be used for analysis. Since retrieval precedes relevance, we shall also provide an overview of how retrievability relates to effectivenessdescribing some of the insights that researchers have discovered thus far. We shall also show how retrievability relates to efficiency, and how the theory of retrievability can be used to improve both effectiveness and efficiency. Then we shall provide an overview of the different applications of retrievability such as Search Engine Bias, Corpus Profiling, etc., before wrapping up with challenges and opportunities. The final session will look at example problems and ways to analyse and apply retrievability to other problems and domains. Participants are invited to bring their own problems to be discussed after the tutorial. This half-day tutorial is ideal for: (i) researchers curious about retrievability and wanting to see how it can impact their research, (ii) researchers who would like to expand their set of analysis techniques, and/or (iii) researchers who would like to use retrievability to perform their own analysis.", "title": "Theory of Retrieval: The Retrievability of Information", "authors": ["Leif Azzopardi"], "year": "2015", "booktitle": "Proceedings of the 2015 International Conference on The Theory of Information Retrieval, ICTIR 2015, Northampton, Massachusetts, USA, September 27-30, 2015"}, "2007.wwwconf_conference-2007.203": {"doc_id": "2007.wwwconf_conference-2007.203", "default_text": "Mirror site maintenance based on evolution associations of web directories ABSTRACTMirroring Web sites is a well-known technique commonly used in the Web community. A mirror site should be updated frequently to ensure that it reflects the content of the original site. Existing mirroring tools apply page-level strategies to check each page of a site, which is inefficient and expensive. In this paper, we propose a novel site-level mirror maintenance strategy. Our approach studies the evolution of Web directory structures and mines association rules between ancestor-descendant Web directories. Discovered rules indicate the evolution correlations between Web directories. Thus, when maintaining the mirror of a Web site (directory), we can optimally skip subdirectories which are negatively correlated with it in undergoing significant changes. The preliminary experimental results show that our approach improves the efficiency of the mirror maintenance process significantly while sacrificing slightly in keeping the \"freshness\" of the mirrors.", "abstract": "ABSTRACTMirroring Web sites is a well-known technique commonly used in the Web community. A mirror site should be updated frequently to ensure that it reflects the content of the original site. Existing mirroring tools apply page-level strategies to check each page of a site, which is inefficient and expensive. In this paper, we propose a novel site-level mirror maintenance strategy. Our approach studies the evolution of Web directory structures and mines association rules between ancestor-descendant Web directories. Discovered rules indicate the evolution correlations between Web directories. Thus, when maintaining the mirror of a Web site (directory), we can optimally skip subdirectories which are negatively correlated with it in undergoing significant changes. The preliminary experimental results show that our approach improves the efficiency of the mirror maintenance process significantly while sacrificing slightly in keeping the \"freshness\" of the mirrors.", "title": "Mirror site maintenance based on evolution associations of web directories", "authors": ["Ling Chen", "Sourav S. Bhowmick", "Wolfgang Nejdl"], "year": "2007", "booktitle": "Proceedings of the 16th International Conference on World Wide Web, WWW 2007, Banff, Alberta, Canada, May 8-12, 2007"}, "2019.wwwconf_conference-2019.152": {"doc_id": "2019.wwwconf_conference-2019.152", "default_text": "Exploiting Diversity in Android TLS Implementations for Mobile App Traffic Classification ", "abstract": "", "title": "Exploiting Diversity in Android TLS Implementations for Mobile App Traffic Classification", "authors": ["Satadal Sengupta", "Niloy Ganguly", "Pradipta De", "Sandip Chakraborty"], "year": "2019", "booktitle": "The World Wide Web Conference, WWW 2019, San Francisco, CA, USA, May 13-17, 2019"}, "2019.wwwconf_conference-2019.217": {"doc_id": "2019.wwwconf_conference-2019.217", "default_text": "Neural IR Meets Graph Embedding: A Ranking Model for Product Search ", "abstract": "", "title": "Neural IR Meets Graph Embedding: A Ranking Model for Product Search", "authors": ["Yuan Zhang", "Dong Wang", "Yan Zhang"], "year": "2019", "booktitle": "The World Wide Web Conference, WWW 2019, San Francisco, CA, USA, May 13-17, 2019"}, "2021.wwwconf_conference-2021.128": {"doc_id": "2021.wwwconf_conference-2021.128", "default_text": "ReACt: A Resource-centric Access Control System for Web-app Interactions on Android ", "abstract": "", "title": "ReACt: A Resource-centric Access Control System for Web-app Interactions on Android", "authors": ["Xin Zhang", "Yifan Zhang"], "year": "2021", "booktitle": "WWW '21: The Web Conference 2021, Virtual Event / Ljubljana, Slovenia, April 19-23, 2021"}, "2014.wwwconf_conference-2014.21": {"doc_id": "2014.wwwconf_conference-2014.21", "default_text": "Reconciling mobile app privacy and usability on smartphones: could user privacy profiles help? ABSTRACTAs they compete for developers, mobile app ecosystems have been exposing a growing number of APIs through their software development kits. Many of these APIs involve accessing sensitive functionality and/or user data and require approval by users. Android for instance allows developers to select from over 130 possible permissions. Expecting users to review and possibly adjust settings related to these permissions has proven unrealistic.In this paper, we report on the results of a study analyzing people's privacy preferences when it comes to granting permissions to different mobile apps. Our results suggest that, while people's mobile app privacy preferences are diverse, a relatively small number of profiles can be identified that offer the promise of significantly simplifying the decisions mobile users have to make. Specifically, our results are based on the analysis of settings of 4.8 million smartphone users of a mobile security and privacy platform. The platform relies on a rooted version of Android where users are allowed to choose between \"granting\", \"denying\" or \"requesting to be dynamically prompted\" when it comes to granting 12 different Android permissions to mobile apps they have downloaded.", "abstract": "ABSTRACTAs they compete for developers, mobile app ecosystems have been exposing a growing number of APIs through their software development kits. Many of these APIs involve accessing sensitive functionality and/or user data and require approval by users. Android for instance allows developers to select from over 130 possible permissions. Expecting users to review and possibly adjust settings related to these permissions has proven unrealistic.In this paper, we report on the results of a study analyzing people's privacy preferences when it comes to granting permissions to different mobile apps. Our results suggest that, while people's mobile app privacy preferences are diverse, a relatively small number of profiles can be identified that offer the promise of significantly simplifying the decisions mobile users have to make. Specifically, our results are based on the analysis of settings of 4.8 million smartphone users of a mobile security and privacy platform. The platform relies on a rooted version of Android where users are allowed to choose between \"granting\", \"denying\" or \"requesting to be dynamically prompted\" when it comes to granting 12 different Android permissions to mobile apps they have downloaded.", "title": "Reconciling mobile app privacy and usability on smartphones: could user privacy profiles help?", "authors": ["Bin Liu", "Jialiu Lin", "Norman M. Sadeh"], "year": "2014", "booktitle": "23rd International World Wide Web Conference, WWW '14, Seoul, Republic of Korea, April 7-11, 2014"}, "2008.wwwconf_conference-2008.132": {"doc_id": "2008.wwwconf_conference-2008.132", "default_text": "Web page rank prediction with markov models ABSTRACTIn this paper we propose a method for predicting the ranking position of a Web page. Assuming a set of successive past top-k rankings, we study the evolution of Web pages in terms of ranking trend sequences used for Markov Models training, which are in turn used to predict future rankings. The predictions are highly accurate for all experimental setups and similarity measures.", "abstract": "ABSTRACTIn this paper we propose a method for predicting the ranking position of a Web page. Assuming a set of successive past top-k rankings, we study the evolution of Web pages in terms of ranking trend sequences used for Markov Models training, which are in turn used to predict future rankings. The predictions are highly accurate for all experimental setups and similarity measures.", "title": "Web page rank prediction with markov models", "authors": ["Michalis Vazirgiannis", "Dimitris Drosos", "Pierre Senellart", "Akrivi Vlachou"], "year": "2008", "booktitle": "Proceedings of the 17th International Conference on World Wide Web, WWW 2008, Beijing, China, April 21-25, 2008"}, "2008.wwwconf_conference-2008.169": {"doc_id": "2008.wwwconf_conference-2008.169", "default_text": "Microscale evolution of web pages ABSTRACTWe track a large set of \"rapidly\" changing web pages and examine the assumption that the arrival of content changes follows a Poisson process on a microscale. We demonstrate that there are significant differences in the behavior of pages that can be exploited to maintain freshness in a web corpus.", "abstract": "ABSTRACTWe track a large set of \"rapidly\" changing web pages and examine the assumption that the arrival of content changes follows a Poisson process on a microscale. We demonstrate that there are significant differences in the behavior of pages that can be exploited to maintain freshness in a web corpus.", "title": "Microscale evolution of web pages", "authors": ["Carrie Grimes"], "year": "2008", "booktitle": "Proceedings of the 17th International Conference on World Wide Web, WWW 2008, Beijing, China, April 21-25, 2008"}, "2008.wwwconf_conference-2008.205": {"doc_id": "2008.wwwconf_conference-2008.205", "default_text": "Visualizing historical content of web pages ABSTRACTRecently, along with the rapid growth of the Web, the preservation efforts have also increased. As a consequence, large amounts of past Web data are stored in Web archives. This historical data can be used for better understanding of long-term page topics and characteristics. In this paper, we propose an interactive visualization system called Page History Explorer for exploring page histories. It allows for roughly portraying evolution of pages and summarizing their content over time. We use a temporal term cloud as a structure for visualizing prevailing and active terms appearing on pages in the past.", "abstract": "ABSTRACTRecently, along with the rapid growth of the Web, the preservation efforts have also increased. As a consequence, large amounts of past Web data are stored in Web archives. This historical data can be used for better understanding of long-term page topics and characteristics. In this paper, we propose an interactive visualization system called Page History Explorer for exploring page histories. It allows for roughly portraying evolution of pages and summarizing their content over time. We use a temporal term cloud as a structure for visualizing prevailing and active terms appearing on pages in the past.", "title": "Visualizing historical content of web pages", "authors": ["Adam Jatowt", "Yukiko Kawai", "Katsumi Tanaka"], "year": "2008", "booktitle": "Proceedings of the 17th International Conference on World Wide Web, WWW 2008, Beijing, China, April 21-25, 2008"}, "2020.wwwconf_conference-2020c.107": {"doc_id": "2020.wwwconf_conference-2020c.107", "default_text": "Event-Related Query Classification with Deep Neural Networks ", "abstract": "", "title": "Event-Related Query Classification with Deep Neural Networks", "authors": ["Sahaj Gandhi", "Behrooz Mansouri", "Ricardo Campos", "Adam Jatowt"], "year": "2020", "booktitle": "Companion of The 2020 Web Conference 2020, Taipei, Taiwan, April 20-24, 2020"}, "2020.wwwconf_conference-2020.154": {"doc_id": "2020.wwwconf_conference-2020.154", "default_text": "MadDroid: Characterizing and Detecting Devious Ad Contents for Android Apps ", "abstract": "", "title": "MadDroid: Characterizing and Detecting Devious Ad Contents for Android Apps", "authors": ["Tianming Liu", "Haoyu Wang", "Li Li", "Xiapu Luo", "Feng Dong", "Yao Guo", "Liu Wang", "Tegawend\u00e9 F. Bissyand\u00e9", "Jacques Klein"], "year": "2020", "booktitle": "WWW '20: The Web Conference 2020, Taipei, Taiwan, April 20-24, 2020"}, "2004.wwwconf_conference-2004.1": {"doc_id": "2004.wwwconf_conference-2004.1", "default_text": "What's new on the web?: the evolution of the web from a search engine perspective ABSTRACTWe seek to gain improved insight into how Web search engines should cope with the evolving Web, in an attempt to provide users with the most up-to-date results possible. For this purpose we collected weekly snapshots of some 150 Web sites over the course of one year, and measured the evolution of content and link structure. Our measurements focus on aspects of potential interest to search engine designers: the evolution of link structure over time, the rate of creation of new pages and new distinct content on the Web, and the rate of change of the content of existing pages under search-centric measures of degree of change.Our findings indicate a rapid turnover rate of Web pages, i.e., high rates of birth and death, coupled with an even higher rate of turnover in the hyperlinks that connect them. For pages that persist over time we found that, perhaps surprisingly, the degree of content shift as measured using TF.IDF cosine distance does not appear to be consistently correlated with the frequency of content updating. Despite this apparent noncorrelation, the rate of content shift of a given page is likely to remain consistent over time. That is, pages that change a great deal in one week will likely change by a similarly large degree in the following week. Conversely, pages that experience little change will continue to experience little change. We conclude the paper with a discussion of the potential implications of our results for the design of effective Web search engines.", "abstract": "ABSTRACTWe seek to gain improved insight into how Web search engines should cope with the evolving Web, in an attempt to provide users with the most up-to-date results possible. For this purpose we collected weekly snapshots of some 150 Web sites over the course of one year, and measured the evolution of content and link structure. Our measurements focus on aspects of potential interest to search engine designers: the evolution of link structure over time, the rate of creation of new pages and new distinct content on the Web, and the rate of change of the content of existing pages under search-centric measures of degree of change.Our findings indicate a rapid turnover rate of Web pages, i.e., high rates of birth and death, coupled with an even higher rate of turnover in the hyperlinks that connect them. For pages that persist over time we found that, perhaps surprisingly, the degree of content shift as measured using TF.IDF cosine distance does not appear to be consistently correlated with the frequency of content updating. Despite this apparent noncorrelation, the rate of content shift of a given page is likely to remain consistent over time. That is, pages that change a great deal in one week will likely change by a similarly large degree in the following week. Conversely, pages that experience little change will continue to experience little change. We conclude the paper with a discussion of the potential implications of our results for the design of effective Web search engines.", "title": "What's new on the web?: the evolution of the web from a search engine perspective", "authors": ["Alexandros Ntoulas", "Junghoo Cho", "Christopher Olston"], "year": "2004", "booktitle": "Proceedings of the 13th international conference on World Wide Web, WWW 2004, New York, NY, USA, May 17-20, 2004"}, "2013.wwwconf_conference-2013c.138": {"doc_id": "2013.wwwconf_conference-2013c.138", "default_text": "Effective analysis, characterization, and detection of malicious web pages ABSTRACTThe steady evolution of the Web has paved the way for miscreants to take advantage of vulnerabilities to embed malicious content into web pages. Up on a visit, malicious web pages steal sensitive data, redirect victims to other malicious targets, or cease control of victim's system to mount future attacks. Approaches to detect malicious web pages have been reactively effective at special classes of attacks like drive-by-downloads. However, the prevalence and complexity of attacks by malicious web pages is still worrisome. The main challenges in this problem domain are (1) fine-grained capturing and characterization of attack payloads (2) evolution of web page artifacts and (3) flexibility and scalability of detection techniques with a fast-changing threat landscape. To this end, we proposed a holistic approach that leverages static analysis, dynamic analysis, machine learning, and evolutionary searching and optimization to effectively analyze and detect malicious web pages. We do so by: introducing novel features to capture fine-grained snapshot of malicious web pages, holistic characterization of malicious web pages, and application of evolutionary techniques to finetune learning-based detection models pertinent to evolution of attack payloads. In this paper, we present key intuition and details of our approach, results obtained so far, and future work.", "abstract": "ABSTRACTThe steady evolution of the Web has paved the way for miscreants to take advantage of vulnerabilities to embed malicious content into web pages. Up on a visit, malicious web pages steal sensitive data, redirect victims to other malicious targets, or cease control of victim's system to mount future attacks. Approaches to detect malicious web pages have been reactively effective at special classes of attacks like drive-by-downloads. However, the prevalence and complexity of attacks by malicious web pages is still worrisome. The main challenges in this problem domain are (1) fine-grained capturing and characterization of attack payloads (2) evolution of web page artifacts and (3) flexibility and scalability of detection techniques with a fast-changing threat landscape. To this end, we proposed a holistic approach that leverages static analysis, dynamic analysis, machine learning, and evolutionary searching and optimization to effectively analyze and detect malicious web pages. We do so by: introducing novel features to capture fine-grained snapshot of malicious web pages, holistic characterization of malicious web pages, and application of evolutionary techniques to finetune learning-based detection models pertinent to evolution of attack payloads. In this paper, we present key intuition and details of our approach, results obtained so far, and future work.", "title": "Effective analysis, characterization, and detection of malicious web pages", "authors": ["Birhanu Eshete"], "year": "2013", "booktitle": "22nd International World Wide Web Conference, WWW '13, Rio de Janeiro, Brazil, May 13-17, 2013, Companion Volume"}, "2018.wwwconf_conference-2018.144": {"doc_id": "2018.wwwconf_conference-2018.144", "default_text": "Aladdin: Automating Release of Deep-Link APIs on Android ABSTRACTCompared to the Web where each web page has a global URL for external access, a specific \"page\" inside a mobile app cannot be easily accessed unless the user performs several steps from the landing page of this app. Recently, the concept of \"deep link\" is expected to be a promising solution and has been advocated by major service providers to enable targeting and opening a specific page of an app externally with an accessible uniform resource identifier. In this paper, we present a large-scale empirical study to investigate how deep links are really adopted, over 25,000 Android apps. To our surprise, we find that deep links have quite low coverage, e.g., more than 70% and 90% of the apps do not have deep links on app stores Wandoujia and Google Play, respectively. One underlying reason is the mandatory and non-trivial manual efforts of app developers to provide APIs for deep links. We then propose the Aladdin approach along with its supporting tool to help developers practically automate the release of deep-link APIs to access locations inside their apps. Aladdin includes a novel cooperative framework by synthesizing the static analysis and the dynamic analysis while minimally engaging developers' inputs and configurations, without requiring any coding efforts or additional deployment efforts. We evaluate Aladdin with 579 popular apps and demonstrate its effectiveness and performance.\nCCS CONCEPTS\u2022 Human-centered computing \u2192 Ubiquitous and mobile computing systems and tools; KEYWORDS Deep link; Android apps; program analysis ACM Reference Format:", "abstract": "ABSTRACTCompared to the Web where each web page has a global URL for external access, a specific \"page\" inside a mobile app cannot be easily accessed unless the user performs several steps from the landing page of this app. Recently, the concept of \"deep link\" is expected to be a promising solution and has been advocated by major service providers to enable targeting and opening a specific page of an app externally with an accessible uniform resource identifier. In this paper, we present a large-scale empirical study to investigate how deep links are really adopted, over 25,000 Android apps. To our surprise, we find that deep links have quite low coverage, e.g., more than 70% and 90% of the apps do not have deep links on app stores Wandoujia and Google Play, respectively. One underlying reason is the mandatory and non-trivial manual efforts of app developers to provide APIs for deep links. We then propose the Aladdin approach along with its supporting tool to help developers practically automate the release of deep-link APIs to access locations inside their apps. Aladdin includes a novel cooperative framework by synthesizing the static analysis and the dynamic analysis while minimally engaging developers' inputs and configurations, without requiring any coding efforts or additional deployment efforts. We evaluate Aladdin with 579 popular apps and demonstrate its effectiveness and performance.\nCCS CONCEPTS\u2022 Human-centered computing \u2192 Ubiquitous and mobile computing systems and tools; KEYWORDS Deep link; Android apps; program analysis ACM Reference Format:", "title": "Aladdin: Automating Release of Deep-Link APIs on Android", "authors": ["Yun Ma", "Ziniu Hu", "Yunxin Liu", "Tao Xie", "Xuanzhe Liu"], "year": "2018", "booktitle": "Proceedings of the 2018 World Wide Web Conference on World Wide Web, WWW 2018, Lyon, France, April 23-27, 2018"}, "2017.wwwconf_conference-2017.20": {"doc_id": "2017.wwwconf_conference-2017.20", "default_text": "An Explorative Study of the Mobile App Ecosystem from App Developers' Perspective ABSTRACTWith the prevalence of smartphones, app markets such as Apple App Store and Google Play has become the center stage in the mobile app ecosystem, with millions of apps developed by tens of thousands of app developers in each major market. This paper presents a study of the mobile app ecosystem from the perspective of app developers. Based on over one million Android apps and 320,000 developers from Google Play, we analyzed the Android app ecosystem from different aspects. Our analysis shows that while over half of the developers have released only one app in the market, many of them have released hundreds of apps. We classified developers into different groups based on the number of apps they have released, and compared their characteristics. Specially, we have analyzed the group of aggressive developers who have released more than 50 apps, trying to understand how and why they create so many apps. We also investigated the privacy behaviors of app developers, showing that some developers have a habit of producing apps with low privacy ratings. Our study shows that understanding the behavior of mobile developers can be helpful to not only other app developers, but also to app markets and mobile users.", "abstract": "ABSTRACTWith the prevalence of smartphones, app markets such as Apple App Store and Google Play has become the center stage in the mobile app ecosystem, with millions of apps developed by tens of thousands of app developers in each major market. This paper presents a study of the mobile app ecosystem from the perspective of app developers. Based on over one million Android apps and 320,000 developers from Google Play, we analyzed the Android app ecosystem from different aspects. Our analysis shows that while over half of the developers have released only one app in the market, many of them have released hundreds of apps. We classified developers into different groups based on the number of apps they have released, and compared their characteristics. Specially, we have analyzed the group of aggressive developers who have released more than 50 apps, trying to understand how and why they create so many apps. We also investigated the privacy behaviors of app developers, showing that some developers have a habit of producing apps with low privacy ratings. Our study shows that understanding the behavior of mobile developers can be helpful to not only other app developers, but also to app markets and mobile users.", "title": "An Explorative Study of the Mobile App Ecosystem from App Developers' Perspective", "authors": ["Haoyu Wang", "Zhe Liu", "Yao Guo", "Xiangqun Chen", "Miao Zhang", "Guoai Xu", "Jason I. Hong"], "year": "2017", "booktitle": "Proceedings of the 26th International Conference on World Wide Web, WWW 2017, Perth, Australia, April 3-7, 2017"}, "2016.wwwconf_conference-2016.119": {"doc_id": "2016.wwwconf_conference-2016.119", "default_text": "Voting with Their Feet: Inferring User Preferences from App Management Activities ABSTRACTSmartphone users have adopted an explosive number of mobile applications (a.k.a., apps) in the recent years. App marketplaces for iOS, Android and Windows Phone platforms host millions of apps which have been downloaded for more than 100 billion times. Investigating how people manage mobile apps in their everyday lives creates a unique opportunity to understand the behavior and preferences of mobile users, to infer the quality of apps, and to improve the user experience. Existing literature provides very limited knowledge about app management activities, due to the lack of user behavioral data at scale. This paper takes the initiative to analyze a very large app management log collected through a leading Android app marketplace. The data set covers five months of detailed downloading, updating, and uninstallation activities, involving 17 million anonymized users and one million apps. We present a surprising finding that the metrics commonly used by app stores to rank apps do not truly reflect the users' real attitudes towards the apps. We then identify useful patterns from the app management activities that much more accurately predict the user preferences of an app even when no user rating is available.", "abstract": "ABSTRACTSmartphone users have adopted an explosive number of mobile applications (a.k.a., apps) in the recent years. App marketplaces for iOS, Android and Windows Phone platforms host millions of apps which have been downloaded for more than 100 billion times. Investigating how people manage mobile apps in their everyday lives creates a unique opportunity to understand the behavior and preferences of mobile users, to infer the quality of apps, and to improve the user experience. Existing literature provides very limited knowledge about app management activities, due to the lack of user behavioral data at scale. This paper takes the initiative to analyze a very large app management log collected through a leading Android app marketplace. The data set covers five months of detailed downloading, updating, and uninstallation activities, involving 17 million anonymized users and one million apps. We present a surprising finding that the metrics commonly used by app stores to rank apps do not truly reflect the users' real attitudes towards the apps. We then identify useful patterns from the app management activities that much more accurately predict the user preferences of an app even when no user rating is available.", "title": "Voting with Their Feet: Inferring User Preferences from App Management Activities", "authors": ["Huoran Li", "Wei Ai", "Xuanzhe Liu", "Jian Tang", "Gang Huang", "Feng Feng", "Qiaozhu Mei"], "year": "2016", "booktitle": "Proceedings of the 25th International Conference on World Wide Web, WWW 2016, Montreal, Canada, April 11 - 15, 2016"}, "2011.trec_conference-2011.102": {"doc_id": "2011.trec_conference-2011.102", "default_text": "The University of Amsterdam at the TREC 2011 Session Track We describe the participation of the University of Amsterdam's ILPS group in the Session track at TREC 2011.", "abstract": "We describe the participation of the University of Amsterdam's ILPS group in the Session track at TREC 2011.", "title": "The University of Amsterdam at the TREC 2011 Session Track", "authors": ["Bouke Huurnink", "Richard Berendsen", "Katja Hofmann", "Edgar Meij", "Maarten de Rijke"], "year": "2011", "booktitle": "Proceedings of The Twentieth Text REtrieval Conference, TREC 2011, Gaithersburg, Maryland, USA, November 15-18, 2011"}, "2012.trec_conference-2012.73": {"doc_id": "2012.trec_conference-2012.73", "default_text": "The University of Amsterdam at TREC 2012 We describe the participation of the University of Amsterdam's ILPS group in the Knowledge Base Acceleration and Microblog tracks at TREC 2012.", "abstract": "We describe the participation of the University of Amsterdam's ILPS group in the Knowledge Base Acceleration and Microblog tracks at TREC 2012.", "title": "The University of Amsterdam at TREC 2012", "authors": ["Richard Berendsen", "Edgar Meij", "Daan Odijk", "Maarten de Rijke", "Wouter Weerkamp"], "year": "2012", "booktitle": "Proceedings of The Twenty-First Text REtrieval Conference, TREC 2012, Gaithersburg, Maryland, USA, November 6-9, 2012"}, "2010.trec_conference-2010.51": {"doc_id": "2010.trec_conference-2010.51", "default_text": "The University of Amsterdam at TREC 2010: Session, Entity and Relevance Feedback ", "abstract": "", "title": "The University of Amsterdam at TREC 2010: Session, Entity and Relevance Feedback", "authors": ["Marc Bron", "Jiyin He", "Katja Hofmann", "Edgar Meij", "Maarten de Rijke", "Manos Tsagkias", "Wouter Weerkamp"], "year": "2010", "booktitle": "Proceedings of The Nineteenth Text REtrieval Conference, TREC 2010, Gaithersburg, Maryland, USA, November 16-19, 2010"}, "2013.trec_conference-2013.23": {"doc_id": "2013.trec_conference-2013.23", "default_text": "Filtering Documents over Time on Evolving Topics - The University of Amsterdam at TREC 2013 KBA CCR ", "abstract": "", "title": "Filtering Documents over Time on Evolving Topics - The University of Amsterdam at TREC 2013 KBA CCR", "authors": ["Tom Kenter"], "year": "2013", "booktitle": "Proceedings of The Twenty-Second Text REtrieval Conference, TREC 2013, Gaithersburg, Maryland, USA, November 19-22, 2013"}, "2018.wwwjournals_journal-ir0anthology0volumeA21A1.5": {"doc_id": "2018.wwwjournals_journal-ir0anthology0volumeA21A1.5", "default_text": "Discovering and understanding android sensor usage behaviors with data flow analysis Abstract Today's Android-powered smartphones have various embedded sensors that measure the acceleration, orientation, light and other environmental conditions. Many functions in the third-party applications (apps) need to use these sensors. However, embedded sensors may lead to security issues, as the third-party apps can read data from these sensors without claiming any permissions. It has been proven that embedded sensors can be exploited by well designed malicious apps, resulting in leaking users' privacy. In this work, we are motivated to provide an overview of sensor usage patterns in current apps by investigating what, why and how embedded sensors are used in the apps collected from both a Chinese app market called \"AppChina\" and the official market called \"Google Play\". To fulfill this goal, We develop a tool called \"SDFDroid\" to identify the used sensors' types and to generate the sensor data propagation graphs in each app. We then cluster the apps to find out their sensor usage patterns based on their sensor data propagation graphs. We apply our method on 22,010 apps collected from AppChina and 7,601 apps from Google Play. Extensive experiments are conducted and the experimental results show that most apps implement their sensor related functions by using the third-party libraries. We further study the sensor usage behaviors in the third-party libraries. Our results show that the accelerometer is the most frequently used sensor. Though many third-party libraries use no more than four types of sensors, there are still some third-party libraries registering all the types of sensors recklessly. These results call for more attentions on better regulating the sensor usage in Android apps.", "abstract": "Abstract Today's Android-powered smartphones have various embedded sensors that measure the acceleration, orientation, light and other environmental conditions. Many functions in the third-party applications (apps) need to use these sensors. However, embedded sensors may lead to security issues, as the third-party apps can read data from these sensors without claiming any permissions. It has been proven that embedded sensors can be exploited by well designed malicious apps, resulting in leaking users' privacy. In this work, we are motivated to provide an overview of sensor usage patterns in current apps by investigating what, why and how embedded sensors are used in the apps collected from both a Chinese app market called \"AppChina\" and the official market called \"Google Play\". To fulfill this goal, We develop a tool called \"SDFDroid\" to identify the used sensors' types and to generate the sensor data propagation graphs in each app. We then cluster the apps to find out their sensor usage patterns based on their sensor data propagation graphs. We apply our method on 22,010 apps collected from AppChina and 7,601 apps from Google Play. Extensive experiments are conducted and the experimental results show that most apps implement their sensor related functions by using the third-party libraries. We further study the sensor usage behaviors in the third-party libraries. Our results show that the accelerometer is the most frequently used sensor. Though many third-party libraries use no more than four types of sensors, there are still some third-party libraries registering all the types of sensors recklessly. These results call for more attentions on better regulating the sensor usage in Android apps.", "title": "Discovering and understanding android sensor usage behaviors with data flow analysis", "authors": ["Xing Liu", "Jiqiang Liu", "Wei Wang", "Yongzhong He", "Xiangliang Zhang"], "year": "2018", "booktitle": "2018 Volume 21 Issue 1"}, "2018.wwwjournals_journal-ir0anthology0volumeA21A1.6": {"doc_id": "2018.wwwjournals_journal-ir0anthology0volumeA21A1.6", "default_text": "An automatically vetting mechanism for SSL error-handling vulnerability in android hybrid Web apps Abstract A large set of diverse hybrid mobile apps, which use both native Android app UIs and Web UIs, are widely available in today's smartphones. These hybrid apps usually use SSL or TLS to secure HTTP based communication. However, researchers show that incorrect implementation of SSL or TLS may lead to serious security problems, such as Man-In-The-Middle (MITM) attacks and phishing attacks. This paper investigates a particular SSL vulnerability that results from error-handling code in the hybrid mobile Web apps. Usually such error-handling code is used to terminate an ongoing communication, but the vulnerability of interest is able to make the communication proceed regardless of SSL certificate verification failures, eventually lead to MITM attacks. To identify those vulnerable apps, we develop a hybrid approach, which combines both static analysis and dynamic analysis to   Web UIs to trigger the error-handling code; (2) accurately select the correct paths from the app entry-point to the targeted code, meanwhile avoiding the crash of apps, and populate messaging objects for the communication between components. Specifically, we construct inter-component call graphs to model the connections, and design algorithms to select the paths from the established graph and determine the parameters by backtracing. To evaluate our approach, we have implemented and tested it with 13,820 real world mobile Web apps from Google Play. The experimental results demonstrate that 1,360 apps are detected as potentially vulnerable ones solely using the static analysis. The dynamic analysis process further confirms that 711 apps are truly vulnerable among the potentially vulnerable set.", "abstract": "Abstract A large set of diverse hybrid mobile apps, which use both native Android app UIs and Web UIs, are widely available in today's smartphones. These hybrid apps usually use SSL or TLS to secure HTTP based communication. However, researchers show that incorrect implementation of SSL or TLS may lead to serious security problems, such as Man-In-The-Middle (MITM) attacks and phishing attacks. This paper investigates a particular SSL vulnerability that results from error-handling code in the hybrid mobile Web apps. Usually such error-handling code is used to terminate an ongoing communication, but the vulnerability of interest is able to make the communication proceed regardless of SSL certificate verification failures, eventually lead to MITM attacks. To identify those vulnerable apps, we develop a hybrid approach, which combines both static analysis and dynamic analysis to   Web UIs to trigger the error-handling code; (2) accurately select the correct paths from the app entry-point to the targeted code, meanwhile avoiding the crash of apps, and populate messaging objects for the communication between components. Specifically, we construct inter-component call graphs to model the connections, and design algorithms to select the paths from the established graph and determine the parameters by backtracing. To evaluate our approach, we have implemented and tested it with 13,820 real world mobile Web apps from Google Play. The experimental results demonstrate that 1,360 apps are detected as potentially vulnerable ones solely using the static analysis. The dynamic analysis process further confirms that 711 apps are truly vulnerable among the potentially vulnerable set.", "title": "An automatically vetting mechanism for SSL error-handling vulnerability in android hybrid Web apps", "authors": ["Yang Liu", "Chaoshun Zuo", "Zonghua Zhang", "Shanqing Guo", "Xin-Shun Xu"], "year": "2018", "booktitle": "2018 Volume 21 Issue 1"}, "2020.tweb_journal-ir0anthology0volumeA14A2.2": {"doc_id": "2020.tweb_journal-ir0anthology0volumeA14A2.2", "default_text": "Image Privacy Prediction Using Deep Neural Networks ", "abstract": "", "title": "Image Privacy Prediction Using Deep Neural Networks", "authors": ["Ashwini Tonge", "Cornelia Caragea"], "year": "2020", "booktitle": "2020 Volume 14 Issue 2"}, "2020.tweb_journal-ir0anthology0volumeA14A3.4": {"doc_id": "2020.tweb_journal-ir0anthology0volumeA14A3.4", "default_text": "Roaming Through the Castle Tunnels: An Empirical Analysis of Inter-app Navigation of Android Apps ", "abstract": "", "title": "Roaming Through the Castle Tunnels: An Empirical Analysis of Inter-app Navigation of Android Apps", "authors": ["Yun Ma", "Ziniu Hu", "Diandian Gu", "Li Zhou", "Qiaozhu Mei", "Gang Huang", "Xuanzhe Liu"], "year": "2020", "booktitle": "2020 Volume 14 Issue 3"}, "2018.ijmir_journal-ir0anthology0volumeA7A1.1": {"doc_id": "2018.ijmir_journal-ir0anthology0volumeA7A1.1", "default_text": "Digital watermarking for deep neural networks ", "abstract": "", "title": "Digital watermarking for deep neural networks", "authors": ["Yuki Nagai", "Yusuke Uchida", "Shigeyuki Sakazawa", "Shin'ichi Satoh"], "year": "2018", "booktitle": "2018 Volume 7 Issue 1"}, "2012.sigirjournals_journal-ir0anthology0volumeA46A1.9": {"doc_id": "2012.sigirjournals_journal-ir0anthology0volumeA46A1.9", "default_text": "Evaluating retrieval models using retrievability measurement AbstractEvaluation is the main driving force in research, development and applications related to information retrieval (IR). In the traditional IR evaluation paradigm a list of query topics along with their relevance judgments are given. The main limitation of this kind of evaluation paradigm is that it focuses almost exclusively on a small set of judged documents and does not consider what influence the given retrieval models have on accessing all the relevant information in the collection. This is particularly important for recall oriented retrieval applications where we want to ensure that that everything relevant has been found.In this thesis we analyze the effectiveness of retrieval models from the documents retrievability point of view. We focus particularly on the retrieval bias of different retrieval models, and try to examine to what extent this bias restricts the users in retrieving relevant information. We explore this research with the help of three factors. First, we analyze the relationship between different characteristics of queries and retrievability. This is important from the query generation point of view, since in case of exhaustive queries, it is practically infeasible to complete retrievability approximation in reasonable time. The strong correlation between retrievability and query characteristics allows us to approximate the retrievability score accurately with the help of a query subset without processing an exhaustive number of queries. After this, we examine to what extent the retrievability and other IR effectiveness measures are related to each other. This specifically helps us to understand to what extent it is possible to automatically rank the effectiveness of retrieval models on the basis of their retrieval bias. This also offers a basis for optimizing retrieval systems for specific collections without the need to provide manually annotated ground truth. This is particularly useful for those retrieval domains where it is difficult to obtain a sufficient amount of relevance judgments. At the end we investigate and devise different retrieval strategies for mitigating the effect of low retrievability of documents. These include collection partitioning and query expansion on the basis of improved pseudo relevance feedback selection.The work present in this thesis provides an a novel approach for the evaluation and optimization of retrieval models particularly for recall oriented retrieval domains, where the focus is on retrieving all relevant information but not just retrieving a subset of relevant information. Available online at: http://www.ifs.tuwien.ac.at/~bashir/shariqbashir_ phd_thesis.pdf", "abstract": "AbstractEvaluation is the main driving force in research, development and applications related to information retrieval (IR). In the traditional IR evaluation paradigm a list of query topics along with their relevance judgments are given. The main limitation of this kind of evaluation paradigm is that it focuses almost exclusively on a small set of judged documents and does not consider what influence the given retrieval models have on accessing all the relevant information in the collection. This is particularly important for recall oriented retrieval applications where we want to ensure that that everything relevant has been found.In this thesis we analyze the effectiveness of retrieval models from the documents retrievability point of view. We focus particularly on the retrieval bias of different retrieval models, and try to examine to what extent this bias restricts the users in retrieving relevant information. We explore this research with the help of three factors. First, we analyze the relationship between different characteristics of queries and retrievability. This is important from the query generation point of view, since in case of exhaustive queries, it is practically infeasible to complete retrievability approximation in reasonable time. The strong correlation between retrievability and query characteristics allows us to approximate the retrievability score accurately with the help of a query subset without processing an exhaustive number of queries. After this, we examine to what extent the retrievability and other IR effectiveness measures are related to each other. This specifically helps us to understand to what extent it is possible to automatically rank the effectiveness of retrieval models on the basis of their retrieval bias. This also offers a basis for optimizing retrieval systems for specific collections without the need to provide manually annotated ground truth. This is particularly useful for those retrieval domains where it is difficult to obtain a sufficient amount of relevance judgments. At the end we investigate and devise different retrieval strategies for mitigating the effect of low retrievability of documents. These include collection partitioning and query expansion on the basis of improved pseudo relevance feedback selection.The work present in this thesis provides an a novel approach for the evaluation and optimization of retrieval models particularly for recall oriented retrieval domains, where the focus is on retrieving all relevant information but not just retrieving a subset of relevant information. Available online at: http://www.ifs.tuwien.ac.at/~bashir/shariqbashir_ phd_thesis.pdf", "title": "Evaluating retrieval models using retrievability measurement", "authors": ["Shariq Bashir"], "year": "2012", "booktitle": "2012 Volume 46 Issue 1"}, "2006.ipm_journal-ir0anthology0volumeA42A1.2": {"doc_id": "2006.ipm_journal-ir0anthology0volumeA42A1.2", "default_text": "A risk minimization framework for information retrieval AbstractThis paper presents a probabilistic information retrieval framework in which the retrieval problem is formally treated as a statistical decision problem. In this framework, queries and documents are modeled using statistical language models, user preferences are modeled through loss functions, and retrieval is cast as a risk minimization problem. We discuss how this framework can unify existing retrieval models and accommodate systematic development of new retrieval models. As an example of using the framework to model non-traditional retrieval problems, we derive retrieval models for subtopic retrieval, which is concerned with retrieving documents to cover many different subtopics of a general query topic. These new models differ from traditional retrieval models in that they relax the traditional assumption of independent relevance of documents.", "abstract": "AbstractThis paper presents a probabilistic information retrieval framework in which the retrieval problem is formally treated as a statistical decision problem. In this framework, queries and documents are modeled using statistical language models, user preferences are modeled through loss functions, and retrieval is cast as a risk minimization problem. We discuss how this framework can unify existing retrieval models and accommodate systematic development of new retrieval models. As an example of using the framework to model non-traditional retrieval problems, we derive retrieval models for subtopic retrieval, which is concerned with retrieving documents to cover many different subtopics of a general query topic. These new models differ from traditional retrieval models in that they relax the traditional assumption of independent relevance of documents.", "title": "A risk minimization framework for information retrieval", "authors": ["ChengXiang Zhai", "John D. Lafferty"], "year": "2006", "booktitle": "2006 Volume 42 Issue 1"}, "2006.ipm_journal-ir0anthology0volumeA42A4.12": {"doc_id": "2006.ipm_journal-ir0anthology0volumeA42A4.12", "default_text": "The effectiveness of Web search engines for retrieving relevant ecommerce links AbstractEcommerce is developing into a fast-growing channel for new business, so a strong presence in this domain could prove essential to the success of numerous commercial organizations. However, there is little research examining ecommerce at the individual customer level, particularly on the success of everyday ecommerce searches. This is critical for the continued success of online commerce. The purpose of this research is to evaluate the effectiveness of search engines in the retrieval of relevant ecommerce links. The study examines the effectiveness of five different types of search engines in response to ecommerce queries by comparing the engines\u00d5 quality of ecommerce links using topical relevancy ratings. This research employs 100 ecommerce queries, five major search engines, and more than 3540 Web links. The findings indicate that links retrieved using an ecommerce search engine are significantly better than those obtained from most other engines types but do not significantly differ from links obtained from a Web directory service. We discuss the implications for Web system design and ecommerce marketing campaigns.", "abstract": "AbstractEcommerce is developing into a fast-growing channel for new business, so a strong presence in this domain could prove essential to the success of numerous commercial organizations. However, there is little research examining ecommerce at the individual customer level, particularly on the success of everyday ecommerce searches. This is critical for the continued success of online commerce. The purpose of this research is to evaluate the effectiveness of search engines in the retrieval of relevant ecommerce links. The study examines the effectiveness of five different types of search engines in response to ecommerce queries by comparing the engines\u00d5 quality of ecommerce links using topical relevancy ratings. This research employs 100 ecommerce queries, five major search engines, and more than 3540 Web links. The findings indicate that links retrieved using an ecommerce search engine are significantly better than those obtained from most other engines types but do not significantly differ from links obtained from a Web directory service. We discuss the implications for Web system design and ecommerce marketing campaigns.", "title": "The effectiveness of Web search engines for retrieving relevant ecommerce links", "authors": ["Bernard J. Jansen", "Paulo R. Molina"], "year": "2006", "booktitle": "2006 Volume 42 Issue 4"}, "2011.tois_journal-ir0anthology0volumeA29A2.0": {"doc_id": "2011.tois_journal-ir0anthology0volumeA29A2.0", "default_text": "Diagnostic Evaluation of Information Retrieval Models Developing effective retrieval models is a long-standing central challenge in information retrieval research. In order to develop more effective models, it is necessary to understand the deficiencies of the current retrieval models and the relative strengths of each of them. In this article, we propose a general methodology to analytically and experimentally diagnose the weaknesses of a retrieval function, which provides guidance on how to further improve its performance. Our methodology is motivated by the empirical observation that good retrieval performance is closely related to the use of various retrieval heuristics. We connect the weaknesses and strengths of a retrieval function with its implementations of these retrieval heuristics, and propose two strategies to check how well a retrieval function implements the desired retrieval heuristics. The first strategy is to formalize heuristics as constraints, and use constraint analysis to analytically check the implementation of retrieval heuristics. The second strategy is to define a set of relevance-preserving perturbations and perform diagnostic tests to empirically evaluate how well a retrieval function implements retrieval heuristics. Experiments show that both strategies are effective to identify the potential problems in implementations of the retrieval heuristics. The performance of retrieval functions can be improved after we fix these problems.", "abstract": "Developing effective retrieval models is a long-standing central challenge in information retrieval research. In order to develop more effective models, it is necessary to understand the deficiencies of the current retrieval models and the relative strengths of each of them. In this article, we propose a general methodology to analytically and experimentally diagnose the weaknesses of a retrieval function, which provides guidance on how to further improve its performance. Our methodology is motivated by the empirical observation that good retrieval performance is closely related to the use of various retrieval heuristics. We connect the weaknesses and strengths of a retrieval function with its implementations of these retrieval heuristics, and propose two strategies to check how well a retrieval function implements the desired retrieval heuristics. The first strategy is to formalize heuristics as constraints, and use constraint analysis to analytically check the implementation of retrieval heuristics. The second strategy is to define a set of relevance-preserving perturbations and perform diagnostic tests to empirically evaluate how well a retrieval function implements retrieval heuristics. Experiments show that both strategies are effective to identify the potential problems in implementations of the retrieval heuristics. The performance of retrieval functions can be improved after we fix these problems.", "title": "Diagnostic Evaluation of Information Retrieval Models", "authors": ["Hui Fang", "Tao Tao", "ChengXiang Zhai"], "year": "2011", "booktitle": "2011 Volume 29 Issue 2"}, "2018.tois_journal-ir0anthology0volumeA36A4.4": {"doc_id": "2018.tois_journal-ir0anthology0volumeA36A4.4", "default_text": "Sentence Relations for Extractive Summarization with Deep Neural Networks ", "abstract": "", "title": "Sentence Relations for Extractive Summarization with Deep Neural Networks", "authors": ["Pengjie Ren", "Zhumin Chen", "Zhaochun Ren", "Furu Wei", "Liqiang Nie", "Jun Ma", "Maarten de Rijke"], "year": "2018", "booktitle": "2018 Volume 36 Issue 4"}}};
  </script>
  <script type="text/javascript">
    var allWeightsA = {};
    var allWeightsB = {};
    var mergedWeights = {};
    var COLOR_A = '236, 154, 8';
    var COLOR_B = '121, 196, 121';
    var singleRunView = (data.meta.run2_name === null);

    function markup(text, weights) {
      weights = weights.filter(function (e) {
        return (e[2] > 0 || typeof e[2] === 'string');
      })
      var $result = $('<div></div>');
      if (weights.length === 0) {
        $result.text(text);
      } else {
        $result.append($('<span></span>').text(text.substring(0, weights[0][0])));
        $.each(weights, function (i, weight) {
          if (typeof weight[2] === 'string') {
            var weightColor = weight[2];
          } else {
            var weightColor = 'rgba(255, 237, 140, ' + weight[2].toString() + ')';
          }
          $result.append($('<mark></mark>').text(text.substring(weight[0], weight[1])).css('background', weightColor).attr("run1", weight[3]).attr("run2", weight[4]));
          if (i + 1 < weights.length) {
            $result.append($('<span></span>').text(text.substring(weight[1], weights[i + 1][0])));
          }
        });
        $result.append($('<span></span>').text(text.substring(weights[weights.length - 1][1], text.length)));
      }
      return $result;
    }

    function colorizeWeights(mergedWeights) {
      // deep copu & handle if doesn't exist
      mergedWeights = mergedWeights ? JSON.parse(JSON.stringify(mergedWeights)) : [];
      var results = mergedWeights.map((segment) => {
        if (!("run2" in segment[2]) || segment[2].run2 === null) {
          return [segment[0], segment[1], 'rgba(' + COLOR_A + ', ' + segment[2].run1.toString() + ')', segment[2].run1, segment[2].run2];
        } else if (!("run" in segment[2]) || segment[2].run1 === null) {
          return [segment[0], segment[1], 'rgba(' + COLOR_B + ', ' + segment[2].run2.toString() + ')', segment[2].run1, segment[2].run2];
        } else {
          var nil = 'rgba(0, 0, 0, 0)'
          var colorA = 'rgba(' + COLOR_A + ', ' + segment[2].run1.toString() + ')';
          var colorB = 'rgba(' + COLOR_B + ', ' + segment[2].run2.toString() + ')';
          var overlapColors = 'linear-gradient(' + colorA + ', ' + nil + '), linear-gradient(' + nil + ', ' + colorB + ')'
          return [segment[0], segment[1], overlapColors, segment[2].run1, segment[2].run2];
        }
      })
      return results;
    }
    function generateDocListSingleView(run, container, oneRunWeights) {
      $(container).empty();
      $(container).css("padding-left", "15%").css("padding-right", "15%");
      $.each(run, function (i, doc) {
        oneRunWeights[doc.doc_id] = doc.weights;
        if (i >= 1 && run[i - 1].rank + 1 != doc.rank) {
          $('<div class="elip"></div>').text('⋮ ' + (doc.rank - run[i - 1].rank - 1).toString() + ' doc(s) skipped').appendTo(container);
        }
        var $did = $('<div class="docid"></div>').append($('<div class="docid-value"></div>').text(doc.doc_id));
        $did.css('background-color', data.meta.relevanceColors[doc.relevance !== null ? doc.relevance.toString() : 'null']).css("right", '0');
        if (doc.relevance === null) {
          var $rel = $('<h6 class="badge badge-info">Unjudged</h6>').css('background-color', data.meta.relevanceColors['null']);
        } else {
          var $rel = $('<h6 class="badge badge-info"></h6>').text('Rel: ' + doc.relevance).css('background-color', data.meta.relevanceColors[doc.relevance.toString()]).attr('title', data.meta.qrelDefs[doc.relevance.toString()]).css('cursor', 'help');
        }
        var $score = $('<h6 class="badge"></h6>').text('Score: ' + doc.score.toFixed(4));
        var doc_fields = data.docs[doc.doc_id];
        var $text = markup(doc_fields[doc.snippet.field].substring(doc.snippet.start, doc.snippet.stop), doc.snippet.weights)
        if (doc.snippet.stop < doc_fields[doc.snippet.field].length) {
          $text.append('...');
        }
        if (doc.snippet.start > 0) {
          $text.prepend('...');
        }
        $text.prepend($('<span style="color: #999;"></span>').text(doc.snippet.field + ': '));
        var newEl = $('<div></div>')
          .append($('<div class="card"></div>')
            .attr('data-docid', doc.doc_id)
            .attr('run1-rank', doc.rank)
            .append($('<div class="card-header"></div>')
              // .css('padding-' + docIdFloat, '30px')
              .append(doc.rank)
              .append(' ')
              .append($did)
              .append(' ')
              .append($rel)
              .append(' ')
              .append($score)
              .append($('<div class="snippet"></div>').append($text))
            )
          )
          .appendTo(container);
      });
    }
    function generateDocList(run, otherRun, container, docIdFloat, allWeights) {
      $(container).empty();
      $.each(run, function (i, doc) {
        allWeights[doc.doc_id] = doc.weights;
        if (i >= 1 && run[i - 1].rank + 1 != doc.rank) {
          $('<div class="elip"></div>').text('⋮ ' + (doc.rank - run[i - 1].rank - 1).toString() + ' doc(s) skipped').appendTo(container);
        }
        var $did = $('<div class="docid"></div>').append($('<div class="docid-value"></div>').text(doc.doc_id));
        $did.css('background-color', data.meta.relevanceColors[doc.relevance !== null ? doc.relevance.toString() : 'null']).css(docIdFloat, '0');
        if (doc.relevance === null) {
          var $rel = $('<h6 class="badge badge-info">Unjudged</h6>').css('background-color', data.meta.relevanceColors['null']);
        } else {
          var $rel = $('<h6 class="badge badge-info"></h6>').text('Rel: ' + doc.relevance).css('background-color', data.meta.relevanceColors[doc.relevance.toString()]).attr('title', data.meta.qrelDefs[doc.relevance.toString()]).css('cursor', 'help');
        }
        var $score = $('<h6 class="badge"></h6>').text('Score: ' + doc.score.toFixed(4));
        var doc_fields = data.docs[doc.doc_id];
        var $text = markup(doc_fields[doc.snippet.field].substring(doc.snippet.start, doc.snippet.stop), doc.snippet.weights)
        if (doc.snippet.stop < doc_fields[doc.snippet.field].length) {
          $text.append('...');
        }
        if (doc.snippet.start > 0) {
          $text.prepend('...');
        }
        $text.prepend($('<span style="color: #999;"></span>').text(doc.snippet.field + ': '));
        // $text.append(' ').append('<a href="#" class="doc-info" role="button">See more</a>');
        var otherRank = null;
        $.each(otherRun, function (i, otherDoc) {
          if (otherDoc.doc_id === doc.doc_id) {
            otherRank = otherDoc.rank;
            return false; // break
          }
        });
        if (otherRank === null) {
          var symbol = '×';
          var tip = 'not ranked in other run';
        }
        else if (doc.rank === otherRank) {
          var symbol = docIdFloat === 'right' ? '→' : '←';
          var tip = 'ranked equally in other run'
        } else if (doc.rank < otherRank) {
          var symbol = docIdFloat === 'right' ? '⬊' : '⬋';
          var tip = 'ranked lower in other run (' + otherRank + ')'
        } else if (doc.rank > otherRank) {
          var symbol = docIdFloat === 'right' ? '⬈' : '⬉';
          var tip = 'ranked higher in other run (' + otherRank + ')'
        }
        var newEl = $('<div></div>')
          // .append($('<span class="other-rank"></span>').text(symbol).css('float', docIdFloat).css('text-align', docIdFloat === 'right' ? 'left' : 'right').attr('title', tip))
          .append($('<div class="card"></div>')
            .attr("run1-rank", docIdFloat === 'right' ? doc.rank : (otherRank === null ? "No" : otherRank))
            .attr("run2-rank", docIdFloat === 'right' ? (otherRank === null ? "No" : otherRank): doc.rank)
            .attr('data-docid', doc.doc_id)
            .append($('<div class="card-header"></div>')
              .css('padding-' + docIdFloat, '30px')
              .append($("<span class='border badge' style='min-width: 50px; font-weight: normal;color: grey;'></span>").html('<span style="font-size: 1.2em;font-weight:bold; color: black;">'+doc.rank +'</span> '+symbol + (otherRank === null ? '': otherRank)).attr('title', tip))
              .append(' ')
              .append($did)
              .append(' ')
              .append($rel)
              .append(' ')
              .append($score)
              .append($('<div class="snippet"></div>').append($text))
            )
          )
          .appendTo(container);
      });
    }

    function selectQuery() {
      var $select = $('#Queries');
      var query_id = $select.val();
      var query = data.queries.filter(query => query.fields.query_id === query_id);
      mergedWeights = query[0].mergedWeights
      var $query = $('#Query');
      $query.empty();
      var $table = $('<table class="fields"></table>').appendTo($query);
      if (query.length > 0) {
        query = query[0];
        $.each(query.fields, function (fname, fvalue) {
          if (fname == "contrast"){
            fvalue = fvalue.name +" (" + fvalue.value.toFixed(3)+")";
            $("#contrast-measure").text("Contrast measure: "+fvalue);
          } else {
            $('<tr></tr>')
            .append($('<th></th>').text(fname))
            .append($('<td></td>').text(fvalue))
            .appendTo($table);
          }
        });
        colors = ["badge-secondary", "badge-info", "badge-warning", "badge-primary"]
        $summary = $("<ul></ul>")
        $.each(query.summary, function(index, data){
          $l=$("<li></li>");
          $.each(data, function(idx, statement){
            $("<span class='badge "+ colors[index] +"'></span>").text(statement).appendTo($l);
          });
          $summary.append($l);
        });
        $("#ranking-summary").empty().append($summary)
        if (singleRunView) {
          var $metricsTable = $('<table class="styled-table" align="center"></table>')
          $("<thead> <tr> <th>Metric</th> <td>Value</td>").appendTo($metricsTable);
          $tbody = $("<tbody></tbody>");
          $.each(query.metrics, function(metric_name, metric_value){
            $('<tr></tr>').append($('<th></th>').text(metric_name))
            .append($('<td></td>').text(metric_value[0]==null? "No" : metric_value[0].toFixed(3)))
            .appendTo($tbody)
          });
          $metricsTable.append($tbody);
          $("#metrics").empty().append($metricsTable);          
          allWeightsA = {}
          generateDocListSingleView(query.run_1, "#docList", allWeightsA);
        } else {
          var $metricsTable = $('<table class="styled-table" align="center"></table>')
          $("<thead> <tr> <th>Metric</th> <td>Run1</td> <td>Run2</td></tr></thead>").appendTo($metricsTable);
          $tbody = $("<tbody></tbody>");
          $.each(query.metrics, function(metric_name, metric_value){
            $('<tr></tr>').append($('<th></th>').text(metric_name))
            .append($('<td></td>').text(metric_value[0] == null? "No" : metric_value[0].toFixed(3)))
            .append($('<td></td>').text(metric_value[1] == null? "No" : metric_value[1].toFixed(3))).appendTo($tbody)
          });
          $metricsTable.append($tbody);
          $("#metrics").empty().append($metricsTable);
          allWeightsA = {};
          allWeightsB = {};          
          generateDocList(query.run_1, query.run_2, '#Run1Docs', 'right', allWeightsA);
          generateDocList(query.run_2, query.run_1, '#Run2Docs', 'left', allWeightsB);          
        }
      }
      var extraFields = $("#Query").find("tr").slice(2).attr("class", "query_collapse collapse");
      // Don't show expand/collapse button if there are not fields to expand/collapse
      $('#query-collapse-btn').toggle(extraFields.length > 0);
    }

    function checkThreshold(value, threshold) {
      if (typeof value !== 'undefined') {
        return parseFloat(value) < threshold;
      } else return true;
    }

    function onChangeWeightThreshold() {
      $("#DocumentDetails mark").removeClass("nobackground")
      var run1Threshold = parseFloat($("#run1Threshold").text());
      var run2Threshold = parseFloat($("#run2Threshold").text());
      $("#DocumentDetails mark").each(function () {
        var run1w = $(this).attr("run1");
        var run2w = $(this).attr("run2");
        if (checkThreshold(run1w, run1Threshold) && checkThreshold(run2w, run2Threshold)) {
          $(this).addClass("nobackground");
        } else if (checkThreshold(run1w, run1Threshold)) {
          $(this).css("background", "rgba(" + COLOR_B + "," + run2w + ")");
        } else if (checkThreshold(run2w, run2Threshold)) {
          $(this).css("background", "rgba(" + COLOR_A + "," + run1w + ")");
        } else {
          $(this).css("background", 'linear-gradient(rgba('+ COLOR_A + "," + run1w + '),  rgba( '+ COLOR_B + "," + run2w + '))');
        }
      })
    }

    function onCardEnter() {
      var did = $(this).attr('data-docid');
      $('.card[data-docid="' + did + '"').addClass('highlight');
    }

    function onCardLeave() {
      var did = $(this).attr('data-docid');
      $('.card.highlight').removeClass('highlight');
    }

    function onDocInfoClick() {
      var docid = $(this).closest('[data-docid]').attr('data-docid');
      var doc = data.docs[docid];
      $('<div id="DocumentOverlay"></div>').appendTo(document.body)
      var page = $('<div id="DocumentDetails" class="sticky-top"></div>')
        .append($('<div class="close-overlay">X</div>').click(closeDoc))
        .appendTo(document.body);
      var legendTable = $('<table class="fields"></table>')
        .appendTo(page);
      var run1Rank = $(this).closest('[run1-rank]').attr('run1-rank');
      legendTable.append($('<tr></tr>')
        .append($('<th></th>').text(data.meta.run1_name))
        .append($('<td></td>')
          .append($('<span class="swatch"></span>').css('background-color', 'rgb(' + COLOR_A + ')'))
        )
        .append($('<td></td>').append($(" <span class='border badge' style='min-width: 70px;'></span>").text("Rank: " +run1Rank)))
        .append($('<td></td>').append($('<form><div class="form-group"><input type="range" class="form-control-range" min="0", max="1.1", step="0.1" value="0.1" id="weightThresholdA"></div></form>').attr("title", "slide to change weight threshold")))
        .append($('<td><span id="run1Threshold" class="badge border rounded threshold-value">0.1</span></td>'))
      );
      if (!singleRunView) {
        var run2Rank = $(this).closest('[run2-rank]').attr('run2-rank');
        legendTable.append($('<tr></tr>')
          .append($('<th></th>').text(data.meta.run2_name))
          .append($('<td></td>')
            .append($('<span class="swatch"></span>').css('background-color', 'rgb(' + COLOR_B + ')'))
          )
          .append($('<td></td>').append($(" <span class='border badge' style='min-width: 70px;'></span>").text("Rank: " +run2Rank)))
          .append($('<td></td>')
            .append($('<form><div class="form-group"><input type="range" class="form-control-range" min="0", max="1.1", step="0.1" value="0.1" id="weightThresholdB"></div></form>').attr("title", "slide to change weight threshold"))
          ).append($('<td><span id="run2Threshold" class="badge border rounded threshold-value">0.1</span></td>'))
        );
        legendTable.append($('<tr></tr>')
          .append($('<th>both</th>'))
          .append($('<td></td>')
            .append($('<span class="swatch"></span>').css('background', 'linear-gradient(rgb(' + COLOR_A + '), rgb(' + COLOR_B + '))'))
          ));
      }
      var fieldTable = $('<table class="fields"></table>')
        .appendTo(page);
      var weightsA = allWeightsA[docid] || {};
      var weightsB = allWeightsB[docid] || {};
      var mweights = mergedWeights[docid] || {};

      $.each(doc, function (fname, fvalue) {
        if (singleRunView) {
          if (!(fname in weightsA)) {
            mweights[fname] = [];
          } else {
            mweights[fname] = weightsA[fname].map(segment => {
              return [segment[0], segment[1], { "run1": segment[2] }];
            });
          }
        }
        var weights = colorizeWeights(mweights[fname]);
        $('<tr></tr>')
          .append($('<th></th>').text(fname))
          .append($('<td></td>').append(markup(fvalue, weights)))
          .appendTo(fieldTable);
      });

      $("input").change(function () {
        var threshold = $(this).closest("form :input").val();
        if ($(this).attr("id") === "weightThresholdA") {
          $("#run1Threshold").text(threshold);
        } else {
          $("#run2Threshold").text(threshold);
        }
        onChangeWeightThreshold();
      });
      onChangeWeightThreshold();
      return false; // prevent nav
    }

    function closeDoc() {
      $('#DocumentOverlay,#DocumentDetails').remove();
    }
    function ding() {
      console.log("Reaching limits! Alert");
    }

    $(function () {
      if (singleRunView) {
        $("#runName").empty();
        $("#runName").append($('<h6 style="text-align: center;"></h6>').text(data.meta.run1_name));
      } else {
        $('#Run1Name').text(data.meta.run1_name);
        $('#Run2Name').text(data.meta.run2_name);
      }
      var $select = $('#Queries');
      var queryDisplayField = null;
      $.each(data.meta.queryFields, function (i, e) {
        if (e !== 'query_id') {
          queryDisplayField = e;
          return false; // break
        }
      });
      $.each(data.queries, function (_, query) {
        if (!singleRunView){
          $('<option>').attr('value', query['fields']['query_id']).attr("data-tokens", query.fields.query_id + " " + query.fields[queryDisplayField]).attr('data-subtext', query.fields.contrast.name+': '+query.fields.contrast.value.toFixed(3)).text(query.fields[queryDisplayField]).appendTo($select);
        } else {
          $('<option>').attr('value', query['fields']['query_id']).text(query.fields[queryDisplayField]).appendTo($select);
        }
      });
      $select.change(selectQuery).change();
      $(document).on('mouseenter', '.card', onCardEnter);
      $(document).on('mouseleave', '.card', onCardLeave);
      $(document).on('click', '.card', onDocInfoClick);
      $(document).on('click', '#DocumentOverlay', closeDoc);
      $(document).keyup(function (e) {
        if (e.key === "Escape") {
          closeDoc();
        }
        if (e.key === "ArrowLeft" && !$("#Queries").is(":focus")) {
          var prev_val = $("#Queries option:selected").prev().val();
          if (typeof prev_val != "undefined") {
            $select.val(prev_val);
            $select.trigger("change");
          } else {
            ding();
          }
        }
        if (e.key === "ArrowRight" && !$("#Queries").is(":focus")) {
          var next_val = $("#Queries option:selected").next().val();
          if (typeof next_val != "undefined") {
            $select.val(next_val);
            $select.trigger("change");
          } else {
            ding();
          }
        }
      });
    });
    $(document).ready(function () {
      var $select = $('#Queries');
      if (data.queries.length > 20)
        $select.attr("data-live-search","true")
      $select.selectpicker();
      $("#Query").find("tr").slice(2).attr("class", "query_collapse collapse")
      $(".query_collapse").on("shown.bs.collapse", function () {
        text = '<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrows-angle-contract" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M.172 15.828a.5.5 0 0 0 .707 0l4.096-4.096V14.5a.5.5 0 1 0 1 0v-3.975a.5.5 0 0 0-.5-.5H1.5a.5.5 0 0 0 0 1h2.768L.172 15.121a.5.5 0 0 0 0 .707zM15.828.172a.5.5 0 0 0-.707 0l-4.096 4.096V1.5a.5.5 0 1 0-1 0v3.975a.5.5 0 0 0 .5.5H14.5a.5.5 0 0 0 0-1h-2.768L15.828.879a.5.5 0 0 0 0-.707z"/></svg>';
        $("#query-collapse-btn").html(text);
      })
      $(".query_collapse").on("hidden.bs.collapse", function () {
        text = '<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrows-angle-expand" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M5.828 10.172a.5.5 0 0 0-.707 0l-4.096 4.096V11.5a.5.5 0 0 0-1 0v3.975a.5.5 0 0 0 .5.5H4.5a.5.5 0 0 0 0-1H1.732l4.096-4.096a.5.5 0 0 0 0-.707zm4.344-4.344a.5.5 0 0 0 .707 0l4.096-4.096V4.5a.5.5 0 1 0 1 0V.525a.5.5 0 0 0-.5-.5H11.5a.5.5 0 0 0 0 1h2.768l-4.096 4.096a.5.5 0 0 0 0 .707z"></svg>';
        $("#query-collapse-btn").html(text);
      })
    })
  </script>
</body>

</html>

